{"title":"spark","uid":"e04902dcdb07e2ad1898c41f1efa8f40","slug":"spark","date":"2022-04-08T12:55:34.000Z","updated":"2022-04-11T08:26:09.220Z","comments":true,"path":"api/articles/spark.json","keywords":null,"cover":[],"content":"<h1 id=\"第3章-spark运行环境\"><a href=\"#第3章-spark运行环境\" class=\"headerlink\" title=\"第3章 spark运行环境\"></a>第3章 spark运行环境</h1><h1 id=\"3-1-local模式\"><a href=\"#3-1-local模式\" class=\"headerlink\" title=\"3.1 local模式\"></a>3.1 local模式</h1><h2 id=\"3-2-standalone模式\"><a href=\"#3-2-standalone模式\" class=\"headerlink\" title=\"3.2 standalone模式\"></a>3.2 standalone模式</h2><h2 id=\"3-3-yarn模式（公司常用）\"><a href=\"#3-3-yarn模式（公司常用）\" class=\"headerlink\" title=\"3.3 yarn模式（公司常用）\"></a>3.3 yarn模式（公司常用）</h2><h2 id=\"3-4-k8s-amp-Mesos模式\"><a href=\"#3-4-k8s-amp-Mesos模式\" class=\"headerlink\" title=\"3.4 k8s &amp; Mesos模式\"></a>3.4 k8s &amp; Mesos模式</h2><h2 id=\"3-5-windows模式\"><a href=\"#3-5-windows模式\" class=\"headerlink\" title=\"3.5 windows模式\"></a>3.5 windows模式</h2><h3 id=\"3-5-2-本地环境\"><a href=\"#3-5-2-本地环境\" class=\"headerlink\" title=\"3.5.2 本地环境\"></a>3.5.2 本地环境</h3><h1 id=\"第4章-spark运行架构\"><a href=\"#第4章-spark运行架构\" class=\"headerlink\" title=\"第4章 spark运行架构\"></a>第4章 spark运行架构</h1><p>Driver 驱动器节点，执行spark任务中的main方法，负责实际的代码执行，任务的调度与管理监控</p>\n<p>Executor：Worker中的一个JVM进程，负责运行具体的任务，任务的实际执行</p>\n<p>Master：资源的调度与分配类似于resourceManager</p>\n<p>Worker：</p>\n<p>AM：解耦Driver 计算 和RM 资源</p>\n<p>RDD的并行度&amp;分区</p>\n<p>makeRDD方法可以传递第二个参数，这个参数表示分区的数量</p>\n<p>第二个参数可以不传递，那么makeRDD会使用默认的数量</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token comment\">//数据如何分配到分区</span>\n\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n\n\n\n\n\n<h1 id=\"第5章-spark核心编程\"><a href=\"#第5章-spark核心编程\" class=\"headerlink\" title=\"第5章 spark核心编程\"></a>第5章 spark核心编程</h1><h2 id=\"5-1-RDD\"><a href=\"#5-1-RDD\" class=\"headerlink\" title=\"5.1 RDD\"></a>5.1 RDD</h2><h3 id=\"5-1-1-什么是RDD\"><a href=\"#5-1-1-什么是RDD\" class=\"headerlink\" title=\"5.1.1 什么是RDD\"></a>5.1.1 什么是RDD</h3><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p> Resilient Distributed Dataset：弹性分布式数据集</p>\n<p>是 Spark 中最基本的数据 处理模型</p>\n<p>代码中是一个<strong>抽象类</strong>，它代表一个<strong>弹性的</strong>、不可变、<strong>可分区</strong>、里面的元素<strong>可并行</strong>计算的集合。</p></blockquote>\n<p>简单一点就是<strong>数据+操作</strong></p>\n<p>逐个解释</p>\n<p>➢ 弹性</p>\n<ul>\n<li><p>存储的弹性：内存与磁盘的自动切换；</p>\n</li>\n<li><p>容错的弹性：数据丢失可以自动恢复； （有副本）</p>\n</li>\n<li><p>计算的弹性：计算出错重试机制； </p>\n</li>\n<li><p>分片的弹性：可根据需要重新分片。 （4个Executor可以改为4个分区）</p>\n</li>\n</ul>\n<p>➢ 分布式：数据存储在大数据集群不同节点上 </p>\n<p>➢ 数据集：RDD 封装了计算逻辑，并不<strong>保存数据</strong> （做完了就把数据发给下一步）</p>\n<p>➢ 数据抽象：RDD 是一个抽象类，需要子类具体实现 </p>\n<p>➢ 不可变：RDD 封装了计算逻辑，是<strong>不可以改变的</strong>，<strong>想要改变，只能产生新的 RDD</strong>，在 新的 RDD 里面封装计算逻辑 </p>\n<p>➢ 可分区、并行计算</p>\n<h3 id=\"5-1-2-核心属性\"><a href=\"#5-1-2-核心属性\" class=\"headerlink\" title=\"5.1.2 核心属性\"></a>5.1.2 核心属性</h3><ul>\n<li><p>分区列表</p>\n</li>\n<li><p>分区计算函数：每一个分区的计算方法</p>\n</li>\n<li><p>与其他RDD的依赖关系</p>\n</li>\n<li><p>分区器（可选）：数据放在哪个分区如我们有HashPartitioner</p>\n</li>\n<li><p>首选位置（可选）：将任务发给Executor时，发向哪一个Executor（就近原则，<strong>移动数据不如移动计算</strong>）</p>\n</li>\n</ul>\n<p>&#x2F;&#x2F; 完整 精简 准确 自己的理解</p>\n<h3 id=\"5-1-3-执行原理\"><a href=\"#5-1-3-执行原理\" class=\"headerlink\" title=\"5.1.3 执行原理\"></a>5.1.3 执行原理</h3><p>1、启动 Yarn 集群环境</p>\n<p><img src=\"https://gitee.com/cencus/blog-image/raw/master/blogImage/1649586103392.png\"></p>\n<p>2、Spark申请资源创建调度节点和计算节点（找人）</p>\n<p><img src=\"https://gitee.com/cencus/blog-image/raw/master/blogImage/1649586122389.png\"></p>\n<p>3、Spark 框架根据需求将计算逻辑根据分区划分成不同的任务（指定任务）</p>\n<p><img src=\"https://gitee.com/cencus/blog-image/raw/master/blogImage/1649586136386.png\"></p>\n<p>4、调度节点将任务根据计算节点状态发送到对应的计算节点进行计算（让员工执行任务）</p>\n<p><img src=\"https://gitee.com/cencus/blog-image/raw/master/blogImage/1649586149384.png\"></p>\n<h3 id=\"5-1-4-基础编程\"><a href=\"#5-1-4-基础编程\" class=\"headerlink\" title=\"5.1.4 基础编程\"></a>5.1.4 基础编程</h3><h4 id=\"5-1-4-1-RDD创建\"><a href=\"#5-1-4-1-RDD创建\" class=\"headerlink\" title=\"5.1.4.1 RDD创建\"></a>5.1.4.1 RDD创建</h4><p>1、从集合（内存）中创建RDD <em>常用</em></p>\n<p>两个方法<code>parallelize</code>和<code>makeRDD</code></p>\n<p>从底层来讲makeRDD就是parallelize只是对其进行了封装，更好记了</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">def</span> makeRDD<span class=\"token punctuation\">[</span>T<span class=\"token operator\">:</span> ClassTag<span class=\"token punctuation\">]</span><span class=\"token punctuation\">(</span>\n\tseq<span class=\"token operator\">:</span> Seq<span class=\"token punctuation\">[</span>T<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n\tnumSlices<span class=\"token operator\">:</span> <span class=\"token builtin\">Int</span> <span class=\"token operator\">=</span> defaultParallelism<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> RDD<span class=\"token punctuation\">[</span>T<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> withScope <span class=\"token punctuation\">&#123;</span>\n    parallelize<span class=\"token punctuation\">(</span>seq<span class=\"token punctuation\">,</span> numSlices<span class=\"token punctuation\">)</span>\n\t<span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n<p>2、从外部存储（文件）创建RDD <em>常用</em></p>\n<p><code>textFile(&quot;path&quot;)</code>方法</p>\n<p>支持的系统：本地FS，HDFS，HBase</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">val</span> fileRDD<span class=\"token operator\">:</span> RDD<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>textFile<span class=\"token punctuation\">(</span><span class=\"token string\">\"path\"</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">//所得是按照行分割的一个集合</span>\n\n<span class=\"token comment\">/*\n其中的path：\n* 目录(目录下的所有文件) 或者 具体文件\n* 通配符 textFile(\"datas/1*.txt\") 所有以1开头的.txt文件\n* 分布式存储路径： \"hdfs://hadoop102:8020/word.txt\"\n* wholeTextFiles() 以文件为单位读取数据，textFile是以行为单位，所得结果为一个turple (文件地址, 内容)\n*/</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n<p>3、从其他RDD创建</p>\n<p>…</p>\n<p>4、直接创建RDD</p>\n<p>…</p>\n<h4 id=\"5-1-4-2-RDD并行度与分区\"><a href=\"#5-1-4-2-RDD并行度与分区\" class=\"headerlink\" title=\"5.1.4.2 RDD并行度与分区\"></a>5.1.4.2 RDD并行度与分区</h4><p>并行度：能够并行计算的任务数量</p>\n<p><code>todo</code>：好像有些东西没有写上</p>\n<h4 id=\"5-1-4-3-RDD转换算子-重点\"><a href=\"#5-1-4-3-RDD转换算子-重点\" class=\"headerlink\" title=\"5.1.4.3 RDD转换算子(重点)\"></a>5.1.4.3 RDD转换算子(重点)</h4><h5 id=\"1-value类型\"><a href=\"#1-value类型\" class=\"headerlink\" title=\"1. value类型\"></a>1. value类型</h5><p>0、一些函数的解释</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\">collect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nforeach<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n\n\n\n<h6 id=\"01、map\"><a href=\"#01、map\" class=\"headerlink\" title=\"01、map\"></a>01、map</h6><p>函数签名：</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">def</span> map<span class=\"token punctuation\">[</span>U<span class=\"token operator\">:</span> ClassTag<span class=\"token punctuation\">]</span><span class=\"token punctuation\">(</span>f<span class=\"token operator\">:</span> T <span class=\"token keyword\">=></span> U<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> RDD<span class=\"token punctuation\">[</span>U<span class=\"token punctuation\">]</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n<p>粗解：传入一个函数，输入是RDD，输入依然是RDD</p>\n<p>模板：</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\">rdd<span class=\"token punctuation\">.</span>map<span class=\"token punctuation\">(</span>\n\telem <span class=\"token keyword\">=></span><span class=\"token punctuation\">&#123;</span>\n        <span class=\"token comment\">//dosomthing</span>\n        <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n        newElem\n    <span class=\"token punctuation\">&#125;</span>\n    \n<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n\n\n<p>对于一个可遍历的rdd，逐个遍历并进行映射转换（就是操作啦）</p>\n<p>map方法，对于集合中的每个元素执行操作<br>    为什么老师说这里没有执行操作而是只是在逐层封装，只有collect才在执行操作，真的没有执行操作，<br>    那说明这些操作是被他们带上了，只有在collect的时候才执行 正确<br>    collect 返回rdd中的所有元素组成的数组，只能用于数据量小的时候，例如所有数据装入外存这种情况<br>     *&#x2F;</p>\n<p>例如想要对rdd里面的每一个元素乘2，就可以像下面这样写</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>atguigu<span class=\"token punctuation\">.</span>bigdata<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>core<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>transform</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span></span>RDD\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">&#123;</span>SparkConf<span class=\"token punctuation\">,</span> SparkContext<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token keyword\">object</span> Spark01_RDD_Operator_Transform <span class=\"token punctuation\">&#123;</span>\n  <span class=\"token keyword\">def</span> main<span class=\"token punctuation\">(</span>args<span class=\"token operator\">:</span> Array<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token keyword\">val</span> sparkConf <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setMaster<span class=\"token punctuation\">(</span><span class=\"token string\">\"local[*]\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"Operator\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">val</span> sc <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkContext<span class=\"token punctuation\">(</span>sparkConf<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//TODO 算子-map</span>\n    <span class=\"token comment\">//需求：将[1,2,3,4]变为[2,4,6,8]</span>\n    <span class=\"token keyword\">val</span> rdd <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">val</span> mapRDD<span class=\"token operator\">:</span> RDD<span class=\"token punctuation\">[</span><span class=\"token builtin\">Int</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> rdd<span class=\"token punctuation\">.</span>map<span class=\"token punctuation\">(</span>_ <span class=\"token operator\">*</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n\n    mapRDD<span class=\"token punctuation\">.</span>collect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>foreach<span class=\"token punctuation\">(</span>println<span class=\"token punctuation\">)</span>\n\n    sc<span class=\"token punctuation\">.</span>stop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n<p>rdd的计算是一个分区内的数据是一个一个的数据执行我们的逻辑，只有前面的一个数据逻辑执行完毕后，才会执行下一个数据，<br>分区内数据的执行是有序的</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>atguigu<span class=\"token punctuation\">.</span>bigdata<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>core<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>transform</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span></span>RDD\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">&#123;</span>SparkConf<span class=\"token punctuation\">,</span> SparkContext<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token keyword\">object</span> Spark01_RDD_Operator_Transform_Par <span class=\"token punctuation\">&#123;</span>\n  <span class=\"token keyword\">def</span> main<span class=\"token punctuation\">(</span>args<span class=\"token operator\">:</span> Array<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token keyword\">val</span> sparkConf <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setMaster<span class=\"token punctuation\">(</span><span class=\"token string\">\"local[*]\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"Operator\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">val</span> sc <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkContext<span class=\"token punctuation\">(</span>sparkConf<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//TODO 算子-map</span>\n    <span class=\"token keyword\">val</span> rdd <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">val</span> mapRDD <span class=\"token operator\">=</span> rdd<span class=\"token punctuation\">.</span>map<span class=\"token punctuation\">(</span>\n      num <span class=\"token keyword\">=></span> <span class=\"token punctuation\">&#123;</span>\n        println<span class=\"token punctuation\">(</span><span class=\"token string\">\">>>>>>> \"</span> <span class=\"token operator\">+</span> num<span class=\"token punctuation\">)</span>\n        num\n      <span class=\"token punctuation\">&#125;</span>\n    <span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">val</span> mapRDD1 <span class=\"token operator\">=</span> mapRDD<span class=\"token punctuation\">.</span>map<span class=\"token punctuation\">(</span>\n      num <span class=\"token keyword\">=></span> <span class=\"token punctuation\">&#123;</span>\n        println<span class=\"token punctuation\">(</span><span class=\"token string\">\"####### \"</span> <span class=\"token operator\">+</span> num<span class=\"token punctuation\">)</span>\n        num\n      <span class=\"token punctuation\">&#125;</span>\n    <span class=\"token punctuation\">)</span>\n    mapRDD1<span class=\"token punctuation\">.</span>collect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    sc<span class=\"token punctuation\">.</span>stop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token punctuation\">&#125;</span>\n\n\n<span class=\"token comment\">/*\n分区1：[1,2]\n分区2: [3,4]\n分区各自独立，可以保证，2不可能再1前面，4不能再3前面\n不同分区之间数据的执行是无序的\n>>>>>>> 3\n>>>>>>> 1\n####### 1\n####### 3\n>>>>>>> 2\n####### 2\n>>>>>>> 4\n####### 4\n\n\n\nrdd的计算是一个分区内的数据是一个一个的数据执行我们的逻辑，只有前面的一个数据逻辑执行完毕后，才会执行下一个数据，\n分区内数据的执行是有序的\nrdd.map(1) => mapRDD.map(1)\nrdd.map(2) => mapRDD.map(2)\nrdd.map(3) => mapRDD.map(3)\nrdd.map(4) => mapRDD.map(4)\n>>>>>>> 1\n####### 1\n>>>>>>> 2\n####### 2\n>>>>>>> 3\n####### 3\n>>>>>>> 4\n####### 4\n\n\n\n */</span>\n\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n<h6 id=\"02、mapPartitions\"><a href=\"#02、mapPartitions\" class=\"headerlink\" title=\"02、mapPartitions\"></a>02、mapPartitions</h6><p>函数签名：</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">def</span> mapPartitions<span class=\"token punctuation\">[</span>U<span class=\"token operator\">:</span> ClassTag<span class=\"token punctuation\">]</span><span class=\"token punctuation\">(</span>\n \tf<span class=\"token operator\">:</span> Iterator<span class=\"token punctuation\">[</span>T<span class=\"token punctuation\">]</span> <span class=\"token keyword\">=></span> Iterator<span class=\"token punctuation\">[</span>U<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n \tpreservesPartitioning<span class=\"token operator\">:</span> <span class=\"token builtin\">Boolean</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> RDD<span class=\"token punctuation\">[</span>U<span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>粗解：传入一个函数：函数的传入类型为迭代类型，返回类型为迭代器</p>\n<p>使用模板：</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\">rdd<span class=\"token punctuation\">.</span>mapPartitions<span class=\"token punctuation\">(</span>\n\titer <span class=\"token keyword\">=></span> <span class=\"token punctuation\">&#123;</span>\n        <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n        newIter <span class=\"token comment\">// List().iterator</span>\n    <span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>我的一些理解：</p>\n<p>将待处理的数据<strong>以分区为单位</strong>发送到计算节点进行处理，这里的处理是指可以进行任意的处 理，哪怕是过滤数据。</p>\n<p>mappartition方法到底在干嘛<br> rdd是一个上述的那种数据集，将rdd以分区为单位进行处理，完了把处理好的返回</p>\n<p>下面是一个使用案例</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>atguigu<span class=\"token punctuation\">.</span>bigdata<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>core<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>transform</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span></span>RDD\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">&#123;</span>SparkConf<span class=\"token punctuation\">,</span> SparkContext<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token keyword\">object</span> Spark02_RDD_Operator_Transform <span class=\"token punctuation\">&#123;</span>\n  <span class=\"token keyword\">def</span> main<span class=\"token punctuation\">(</span>args<span class=\"token operator\">:</span> Array<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token keyword\">val</span> sparkConf <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setMaster<span class=\"token punctuation\">(</span><span class=\"token string\">\"local[*]\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"Operator\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">val</span> sc <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkContext<span class=\"token punctuation\">(</span>sparkConf<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//TODO 算子-map</span>\n    <span class=\"token keyword\">val</span> rdd <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//高性能做法，将一个分区全部拿到以后再做操作，而不是一个一个做操作</span>\n    <span class=\"token keyword\">val</span> mapRDD <span class=\"token operator\">=</span> rdd<span class=\"token punctuation\">.</span>mapPartitions<span class=\"token punctuation\">(</span>\n      iter <span class=\"token keyword\">=></span> <span class=\"token punctuation\">&#123;</span>\n        println<span class=\"token punctuation\">(</span><span class=\"token string\">\">>>>>>>>>>>>>>>\"</span><span class=\"token punctuation\">)</span>\n        iter<span class=\"token punctuation\">.</span>map<span class=\"token punctuation\">(</span>_ <span class=\"token operator\">*</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n      <span class=\"token punctuation\">&#125;</span>\n    <span class=\"token punctuation\">)</span>\n\n    mapRDD<span class=\"token punctuation\">.</span>collect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>foreach<span class=\"token punctuation\">(</span>println<span class=\"token punctuation\">)</span>\n\n    sc<span class=\"token punctuation\">.</span>stop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token punctuation\">&#125;</span>\n\n\n<span class=\"token comment\">/*\nmappartitions类似缓冲\n说明执行了两次，因为有两个分区，一次把一个分区拿过来，放在内存计算，类似于批处理，\n>>>>>>>>>>>>>>>\n>>>>>>>>>>>>>>>\n2\n4\n6\n8\n但是不好的地方：\n* 当一个分区没有计算完成，比如说 10000条数据计算了999条，这999条不会释放，因为存在对象的引用\n* 在内存较小，数据量较大的场景下容易出现内存移除，这种情况下还是用map\n */</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>案例返回每个数据分区的最大值</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>atguigu<span class=\"token punctuation\">.</span>bigdata<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>core<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>transform</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">&#123;</span>SparkConf<span class=\"token punctuation\">,</span> SparkContext<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token keyword\">object</span> Spark02_RDD_Operator_Transform_Test <span class=\"token punctuation\">&#123;</span>\n  <span class=\"token keyword\">def</span> main<span class=\"token punctuation\">(</span>args<span class=\"token operator\">:</span> Array<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token keyword\">val</span> sparkConf <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setMaster<span class=\"token punctuation\">(</span><span class=\"token string\">\"local[*]\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"Operator\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">val</span> sc <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkContext<span class=\"token punctuation\">(</span>sparkConf<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//TODO 算子-map</span>\n    <span class=\"token keyword\">val</span> rdd <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n      \n    <span class=\"token comment\">//需求获取每个分区的最大值</span>\n    <span class=\"token keyword\">val</span> mapRDD <span class=\"token operator\">=</span> rdd<span class=\"token punctuation\">.</span>mapPartitions<span class=\"token punctuation\">(</span>\n      iter <span class=\"token keyword\">=></span> <span class=\"token punctuation\">&#123;</span>\n        List<span class=\"token punctuation\">(</span>iter<span class=\"token punctuation\">.</span>max<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>iterator\n      <span class=\"token punctuation\">&#125;</span>\n    <span class=\"token punctuation\">)</span>\n\n    mapRDD<span class=\"token punctuation\">.</span>collect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>foreach<span class=\"token punctuation\">(</span>println<span class=\"token punctuation\">)</span>\n      \n    sc<span class=\"token punctuation\">.</span>stop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n<p>map与mapPartitions的区别</p>\n<table>\n<thead>\n<tr>\n<th>角度</th>\n<th>map</th>\n<th>mapPartitions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>数据处理角度</td>\n<td>Map 算子是分区内一个数据一个数据的执行，类似于<strong>串行操作</strong></td>\n<td>mapPartitions 算子 是以分区为单位进行<strong>批处理操作</strong></td>\n</tr>\n<tr>\n<td>功能的角度</td>\n<td>Map 算子主要目的将数据源中的数据进行<strong>转换和改变</strong>。但是不会<strong>减少或增多数据</strong></td>\n<td>MapPartitions 算子需要传递一个迭代器，返回一个迭代器，<strong>没有要求的元素的个数保持不变， 所以可以增加或减少数据</strong></td>\n</tr>\n<tr>\n<td>性能的角度</td>\n<td>Map 算子因为类似于串行操作，所以性能比较<strong>低</strong></td>\n<td>mapPartitions 算子类似于批处 理，所以性能较<strong>高</strong><br />但是 mapPartitions 算子会长时间占用内存，那么这样会导致内存可能 不够用，出现内存溢出的错误。所以<strong>在内存有限的情况下，不推荐使用</strong>。使用 map 操作替代</td>\n</tr>\n</tbody></table>\n<h6 id=\"03、mapPartitionsWithIndex\"><a href=\"#03、mapPartitionsWithIndex\" class=\"headerlink\" title=\"03、mapPartitionsWithIndex\"></a>03、mapPartitionsWithIndex</h6><h6 id=\"04、flatMap\"><a href=\"#04、flatMap\" class=\"headerlink\" title=\"04、flatMap\"></a>04、flatMap</h6><p>扁平化处理，是不是听不懂，像这种list里面嵌套了list的结构，就可以用这种方式去做处理把<code>List(List(1,2), List(3,4))</code>变成 <code>List(1,2,3,4)</code></p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">val</span> rdd <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> List<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">//</span>\n\nrdd<span class=\"token punctuation\">.</span>flatMap<span class=\"token punctuation\">(</span>\n list <span class=\"token keyword\">=></span> <span class=\"token punctuation\">&#123;</span>\n     <span class=\"token comment\">//do something</span>\n     new_list\n <span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n\n\n<h6 id=\"05、glom\"><a href=\"#05、glom\" class=\"headerlink\" title=\"05、glom\"></a>05、glom</h6><h6 id=\"06、groupBy\"><a href=\"#06、groupBy\" class=\"headerlink\" title=\"06、groupBy\"></a>06、groupBy</h6><h6 id=\"07、filter\"><a href=\"#07、filter\" class=\"headerlink\" title=\"07、filter\"></a>07、filter</h6><h6 id=\"08、sample\"><a href=\"#08、sample\" class=\"headerlink\" title=\"08、sample\"></a>08、sample</h6><h6 id=\"09、distinct\"><a href=\"#09、distinct\" class=\"headerlink\" title=\"09、distinct\"></a>09、distinct</h6><h6 id=\"10、coalesce\"><a href=\"#10、coalesce\" class=\"headerlink\" title=\"10、coalesce\"></a>10、coalesce</h6><h6 id=\"11、repartition\"><a href=\"#11、repartition\" class=\"headerlink\" title=\"11、repartition\"></a>11、repartition</h6><h6 id=\"12、sortBy\"><a href=\"#12、sortBy\" class=\"headerlink\" title=\"12、sortBy\"></a>12、sortBy</h6><h5 id=\"2-双value类型\"><a href=\"#2-双value类型\" class=\"headerlink\" title=\"2. 双value类型\"></a>2. 双value类型</h5><h6 id=\"01、intersection\"><a href=\"#01、intersection\" class=\"headerlink\" title=\"01、intersection\"></a>01、intersection</h6><h6 id=\"02、union\"><a href=\"#02、union\" class=\"headerlink\" title=\"02、union\"></a>02、union</h6><h6 id=\"03、subtract\"><a href=\"#03、subtract\" class=\"headerlink\" title=\"03、subtract\"></a>03、subtract</h6><h6 id=\"04、zip\"><a href=\"#04、zip\" class=\"headerlink\" title=\"04、zip\"></a>04、zip</h6><h5 id=\"3-key-value类型\"><a href=\"#3-key-value类型\" class=\"headerlink\" title=\"3. key-value类型\"></a>3. key-value类型</h5><h6 id=\"01、partitionBy\"><a href=\"#01、partitionBy\" class=\"headerlink\" title=\"01、partitionBy\"></a>01、partitionBy</h6><pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>atguigu<span class=\"token punctuation\">.</span>bigdata<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>core<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>transform</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span></span>RDD\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">&#123;</span>HashPartitioner<span class=\"token punctuation\">,</span> SparkConf<span class=\"token punctuation\">,</span> SparkContext<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token keyword\">object</span> Spark14_RDD_Operator_Transform <span class=\"token punctuation\">&#123;</span>\n  <span class=\"token keyword\">def</span> main<span class=\"token punctuation\">(</span>args<span class=\"token operator\">:</span> Array<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token keyword\">val</span> sparkConf <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setMaster<span class=\"token punctuation\">(</span><span class=\"token string\">\"local[*]\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"Operator\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">val</span> sc <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkContext<span class=\"token punctuation\">(</span>sparkConf<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//TODO Key-Value类型</span>\n\n    <span class=\"token keyword\">val</span> rdd <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">val</span> mapRDD<span class=\"token operator\">:</span> RDD<span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">Int</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">Int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> rdd<span class=\"token punctuation\">.</span>map<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>_<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">//把数值变成了turple类型，对偶元组可以使用了</span>\n\n    <span class=\"token comment\">//该方法不是rdd的是pairrddfunctions方法</span>\n    <span class=\"token comment\">//RDD[T]中T的写法就直接写里面的元素的类型</span>\n    <span class=\"token comment\">//scala中的隐式转换，查找转换规则，可以简单理解为二次编译</span>\n\n    <span class=\"token comment\">/*\n    implicit def rddToPairRDDFunctions[K, V](rdd: RDD[(K, V)])\n    (implicit kt: ClassTag[K], vt: ClassTag[V], ord: Ordering[K] = null): PairRDDFunctions[K, V] = &#123;\n    new PairRDDFunctions(rdd)\n  &#125;\n  隐式函数，rdd转换为PairRDDFunctions 遵循了OCP开发原则开放封闭原则（OCP，Open Closed Principle）是所有 面向对象 原则的核心。 软件设计本身所追求的目标就是**封装变化、降低耦合**，而开放封闭原则正是对这一目标的最直接体现。 其他的设计原则，很多时候是为实现这一目标服务的，例如以Liskov替换原则实现最佳的、正确的继承层次，就能保证不会违反开放封闭原则。 软件实体应该是可扩展，而不可修改的。\n\n     */</span>\n    <span class=\"token comment\">//改变数据所在的分区</span>\n    mapRDD<span class=\"token punctuation\">.</span>partitionBy<span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> HashPartitioner<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n      <span class=\"token punctuation\">.</span>saveAsTextFile<span class=\"token punctuation\">(</span><span class=\"token string\">\"output\"</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//ctrl + h查看当前所在类的实现类</span>\n\n\n\n\n    <span class=\"token comment\">//打开之后24一个分区，13一个分区，为什么呢？</span>\n    <span class=\"token comment\">/*\n    def getPartition(key: Any): Int = key match &#123;\n    case null => 0\n    case _ => Utils.nonNegativeMod(key.hashCode, numPartitions)\n  &#125;\n  def nonNegativeMod(x: Int, mod: Int): Int = &#123;\n    val rawMod = x % mod\n    rawMod + (if (rawMod &lt; 0) mod else 0)\n  &#125;\n     */</span>\n\n\n\n    sc<span class=\"token punctuation\">.</span>stop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<h6 id=\"02、reduceByKey\"><a href=\"#02、reduceByKey\" class=\"headerlink\" title=\"02、reduceByKey\"></a>02、reduceByKey</h6><p>粗解：</p>\n<p>相同的key分在同一个组，对其value做两两聚合</p>\n<p>如下述情况，聚合方式写在了注释中</p>\n<p>格式：</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token comment\">//一般形式</span>\nrdd<span class=\"token punctuation\">.</span>reduceByKey<span class=\"token punctuation\">(</span>\n    <span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span> <span class=\"token keyword\">=></span> <span class=\"token punctuation\">&#123;</span>\n        <span class=\"token comment\">//将xy聚合的操作，如x + y</span>\n        x <span class=\"token operator\">+</span> y\n    <span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">)</span>\n<span class=\"token comment\">//简写只需要写两个数的操作方式</span>\nrdd<span class=\"token punctuation\">.</span>reduceByKey<span class=\"token punctuation\">(</span>_<span class=\"token operator\">+</span>_<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>atguigu<span class=\"token punctuation\">.</span>bigdata<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>core<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>transform</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span></span>RDD\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">&#123;</span>HashPartitioner<span class=\"token punctuation\">,</span> SparkConf<span class=\"token punctuation\">,</span> SparkContext<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token keyword\">object</span> Spark15_RDD_Operator_Transform <span class=\"token punctuation\">&#123;</span>\n  <span class=\"token keyword\">def</span> main<span class=\"token punctuation\">(</span>args<span class=\"token operator\">:</span> Array<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token keyword\">val</span> sparkConf <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setMaster<span class=\"token punctuation\">(</span><span class=\"token string\">\"local[*]\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"Operator\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">val</span> sc <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkContext<span class=\"token punctuation\">(</span>sparkConf<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//TODO Key-Value类型</span>\n    <span class=\"token keyword\">val</span> rdd <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span>\n      <span class=\"token punctuation\">(</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"b\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//需求：相同的key分在同一个组，对其value做聚合</span>\n    <span class=\"token comment\">//相同的key的数据进行value的聚合操作 又涉及到了分组的概念</span>\n    <span class=\"token comment\">//scala中聚合操作一般都是两两聚合，spark也是</span>\n    <span class=\"token comment\">//[1,2,3]</span>\n    <span class=\"token comment\">//[3,3]</span>\n    <span class=\"token comment\">//[6]</span>\n    <span class=\"token comment\">//reduceByKey中，如果key的数据只有一个，是不会参与运算的</span>\n\n    <span class=\"token comment\">//底层用了hashpartition</span>\n    <span class=\"token keyword\">val</span> reduceRDD <span class=\"token operator\">=</span> rdd<span class=\"token punctuation\">.</span>reduceByKey<span class=\"token punctuation\">(</span>\n      <span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span> <span class=\"token keyword\">=></span> <span class=\"token punctuation\">&#123;</span>\n        println<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token id function\">s</span><span class=\"token string\">\"x=</span><span class=\"token interpolation\"><span class=\"token punctuation\">$</span><span class=\"token expression\">x</span></span><span class=\"token string\">,y=</span><span class=\"token interpolation\"><span class=\"token punctuation\">$</span><span class=\"token expression\">y</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">+</span> y\n      <span class=\"token punctuation\">&#125;</span>\n    <span class=\"token punctuation\">)</span>\n\n    reduceRDD<span class=\"token punctuation\">.</span>collect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>foreach<span class=\"token punctuation\">(</span>println<span class=\"token punctuation\">)</span>\n\n\n    sc<span class=\"token punctuation\">.</span>stop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<h6 id=\"03、groupByKey\"><a href=\"#03、groupByKey\" class=\"headerlink\" title=\"03、groupByKey\"></a>03、groupByKey</h6><p>将数据源中相同key的数据分在一个组中，形成一个对偶元组 <code>(key, 相同key的value的可迭代集合)</code></p>\n<p>格式：</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\">rdd<span class=\"token punctuation\">.</span>groupByKey<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">//直接按照key来分组，底层用到了HashPartitioner</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n\n\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>atguigu<span class=\"token punctuation\">.</span>bigdata<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>core<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>transform</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">&#123;</span>SparkConf<span class=\"token punctuation\">,</span> SparkContext<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token keyword\">object</span> Spark16_RDD_Operator_Transform <span class=\"token punctuation\">&#123;</span>\n  <span class=\"token keyword\">def</span> main<span class=\"token punctuation\">(</span>args<span class=\"token operator\">:</span> Array<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token keyword\">val</span> sparkConf <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setMaster<span class=\"token punctuation\">(</span><span class=\"token string\">\"local[*]\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"Operator\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">val</span> sc <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkContext<span class=\"token punctuation\">(</span>sparkConf<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//TODO Key-Value类型</span>\n    <span class=\"token keyword\">val</span> rdd <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span>\n      <span class=\"token punctuation\">(</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"b\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//将数据源中相同key的数据分在一个组中，形成一个对偶元组</span>\n    <span class=\"token comment\">//(key, 相同key的value的可迭代集合)</span>\n    <span class=\"token comment\">//(a,CompactBuffer(1, 2, 3))</span>\n    <span class=\"token comment\">//(b,CompactBuffer(4))</span>\n\n    <span class=\"token keyword\">val</span> groupRDD <span class=\"token operator\">=</span> rdd<span class=\"token punctuation\">.</span>groupByKey<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n\n    <span class=\"token comment\">//groupBy</span>\n    <span class=\"token comment\">//</span>\n    <span class=\"token comment\">//val groupRDD = rdd.groupBy(_._1)</span>\n\n    groupRDD<span class=\"token punctuation\">.</span>collect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>foreach<span class=\"token punctuation\">(</span>println<span class=\"token punctuation\">)</span>\n\n    sc<span class=\"token punctuation\">.</span>stop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token punctuation\">&#125;</span>\n<span class=\"token comment\">/*\n使用什么分组不确定，groupby要传进去，groupbykey不用\n得到的结果而言：一个是(key,value的集合)\n一个是(key,(key,value)的集合)\n */</span>\n\n<span class=\"token comment\">/*\ngroupByKey会导致数据打乱重组，涉及shuffle\nspark中的shuffle操作必须要落盘处理，不能在内存中数据等待，否则会越积越多，导致内存溢出\n落盘涉及磁盘I/O，会影响性能，所以shuffle的性能很低\n */</span>\n\n<span class=\"token comment\">/*\nreduceByKey支持分区内预聚合功能，可以有效减少shuffle时的落盘量，提高性能\n */</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>与groupBy的区别</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>atguigu<span class=\"token punctuation\">.</span>bigdata<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>core<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>transform</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">&#123;</span>SparkConf<span class=\"token punctuation\">,</span> SparkContext<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token keyword\">object</span> Spark16_RDD_Operator_Transform <span class=\"token punctuation\">&#123;</span>\n  <span class=\"token keyword\">def</span> main<span class=\"token punctuation\">(</span>args<span class=\"token operator\">:</span> Array<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token keyword\">val</span> sparkConf <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setMaster<span class=\"token punctuation\">(</span><span class=\"token string\">\"local[*]\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"Operator\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">val</span> sc <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkContext<span class=\"token punctuation\">(</span>sparkConf<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//TODO Key-Value类型</span>\n    <span class=\"token keyword\">val</span> rdd <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span>\n      <span class=\"token punctuation\">(</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"b\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n      \n    <span class=\"token keyword\">val</span> groupRDD <span class=\"token operator\">=</span> rdd<span class=\"token punctuation\">.</span>groupBy<span class=\"token punctuation\">(</span>_<span class=\"token punctuation\">.</span>_1<span class=\"token punctuation\">)</span>\n\n    groupRDD<span class=\"token punctuation\">.</span>collect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>foreach<span class=\"token punctuation\">(</span>println<span class=\"token punctuation\">)</span>\n\n    sc<span class=\"token punctuation\">.</span>stop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token punctuation\">&#125;</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<table>\n<thead>\n<tr>\n<th>角度</th>\n<th>groupBy</th>\n<th>groupByKey</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>分组方式</td>\n<td>传参</td>\n<td>不用</td>\n</tr>\n<tr>\n<td>结果</td>\n<td>(key,value的集合)</td>\n<td>(key,(key,value)的集合)</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<p>面试题：reduceByKey和groupByKey的区别</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><ul>\n<li>spark中的shuffle操作必须要<strong>落盘处理</strong>，不能在内存中数据等待，否则会越积越多，导致内存溢出<br>落盘涉及磁盘I&#x2F;O，会影响性能，所以<strong>shuffle的性能很低</strong></li>\n<li>reduceByKey支持<strong>分区内预聚合</strong>功能，可以有效减少shuffle时的落盘量，<strong>提高性能</strong></li>\n</ul></blockquote>\n<table>\n<thead>\n<tr>\n<th>角度</th>\n<th>reduceByKey</th>\n<th>groupByKey</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>从 shuffle 的角度</td>\n<td><strong>reduceByKey 和 groupByKey 都存在 shuffle 的操作</strong>，但是 reduceByKey 可以在 shuffle 前对分区内相同 key 的数据进行<strong>预聚合</strong>（combine）功能，这样会减少落盘的 数据量，reduceByKey <strong>性能比较高</strong>。</td>\n<td>而 groupByKey 只是进行分组，不存在数据量减少的问题</td>\n</tr>\n<tr>\n<td>从功能的角度</td>\n<td>reduceByKey 其实包含分组和聚合的功能<br />所以在<strong>分组聚合</strong>的场合下，推荐使用 reduceByKey</td>\n<td>GroupByKey 只能分组，不能聚合<br />如果<strong>仅仅是分组而不需要聚合</strong>那么还是只能使用 groupByKey</td>\n</tr>\n</tbody></table>\n<h6 id=\"04、aggregateByKey\"><a href=\"#04、aggregateByKey\" class=\"headerlink\" title=\"04、aggregateByKey\"></a>04、aggregateByKey</h6><h6 id=\"05、foldByKey\"><a href=\"#05、foldByKey\" class=\"headerlink\" title=\"05、foldByKey\"></a>05、foldByKey</h6><h6 id=\"06、combineByKey\"><a href=\"#06、combineByKey\" class=\"headerlink\" title=\"06、combineByKey\"></a>06、combineByKey</h6><h6 id=\"07、sortByKey\"><a href=\"#07、sortByKey\" class=\"headerlink\" title=\"07、sortByKey\"></a>07、sortByKey</h6><h6 id=\"08、join\"><a href=\"#08、join\" class=\"headerlink\" title=\"08、join\"></a>08、join</h6><h6 id=\"09、leftOuterJoin\"><a href=\"#09、leftOuterJoin\" class=\"headerlink\" title=\"09、leftOuterJoin\"></a>09、leftOuterJoin</h6><h6 id=\"10、cogroup\"><a href=\"#10、cogroup\" class=\"headerlink\" title=\"10、cogroup\"></a>10、cogroup</h6><h1 id=\"一些报错及解决\"><a href=\"#一些报错及解决\" class=\"headerlink\" title=\"一些报错及解决\"></a>一些报错及解决</h1><p>1、报错奇奇怪怪的：����: �Ҳ������޷���������<br>在maven的runner中</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20210323104253642.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmd5dWUwMzM=,size_16,color_FFFFFF,t_70#pic_center\"></p>\n","feature":true,"text":"第3章 spark运行环境3.1 local模式3.2 standalone模式3.3 yarn模式（公司常用）3.4 k8s &amp; Mesos模式3.5 windows模式3.5.2 本地环境第4章 spark运行架构Driver 驱动器节点，执行spark任务中的mai...","link":"","photos":[],"count_time":{"symbolsCount":"12k","symbolsTime":"11 mins."},"categories":[],"tags":[{"name":"spark","slug":"spark","count":1,"path":"api/tags/spark.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E7%AC%AC3%E7%AB%A0-spark%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83\"><span class=\"toc-text\">第3章 spark运行环境</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#3-1-local%E6%A8%A1%E5%BC%8F\"><span class=\"toc-text\">3.1 local模式</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-2-standalone%E6%A8%A1%E5%BC%8F\"><span class=\"toc-text\">3.2 standalone模式</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-3-yarn%E6%A8%A1%E5%BC%8F%EF%BC%88%E5%85%AC%E5%8F%B8%E5%B8%B8%E7%94%A8%EF%BC%89\"><span class=\"toc-text\">3.3 yarn模式（公司常用）</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-4-k8s-amp-Mesos%E6%A8%A1%E5%BC%8F\"><span class=\"toc-text\">3.4 k8s &amp; Mesos模式</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-5-windows%E6%A8%A1%E5%BC%8F\"><span class=\"toc-text\">3.5 windows模式</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#3-5-2-%E6%9C%AC%E5%9C%B0%E7%8E%AF%E5%A2%83\"><span class=\"toc-text\">3.5.2 本地环境</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E7%AC%AC4%E7%AB%A0-spark%E8%BF%90%E8%A1%8C%E6%9E%B6%E6%9E%84\"><span class=\"toc-text\">第4章 spark运行架构</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E7%AC%AC5%E7%AB%A0-spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B\"><span class=\"toc-text\">第5章 spark核心编程</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#5-1-RDD\"><span class=\"toc-text\">5.1 RDD</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#5-1-1-%E4%BB%80%E4%B9%88%E6%98%AFRDD\"><span class=\"toc-text\">5.1.1 什么是RDD</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#5-1-2-%E6%A0%B8%E5%BF%83%E5%B1%9E%E6%80%A7\"><span class=\"toc-text\">5.1.2 核心属性</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#5-1-3-%E6%89%A7%E8%A1%8C%E5%8E%9F%E7%90%86\"><span class=\"toc-text\">5.1.3 执行原理</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#5-1-4-%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B\"><span class=\"toc-text\">5.1.4 基础编程</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#5-1-4-1-RDD%E5%88%9B%E5%BB%BA\"><span class=\"toc-text\">5.1.4.1 RDD创建</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#5-1-4-2-RDD%E5%B9%B6%E8%A1%8C%E5%BA%A6%E4%B8%8E%E5%88%86%E5%8C%BA\"><span class=\"toc-text\">5.1.4.2 RDD并行度与分区</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#5-1-4-3-RDD%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90-%E9%87%8D%E7%82%B9\"><span class=\"toc-text\">5.1.4.3 RDD转换算子(重点)</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#1-value%E7%B1%BB%E5%9E%8B\"><span class=\"toc-text\">1. value类型</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#01%E3%80%81map\"><span class=\"toc-text\">01、map</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#02%E3%80%81mapPartitions\"><span class=\"toc-text\">02、mapPartitions</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#03%E3%80%81mapPartitionsWithIndex\"><span class=\"toc-text\">03、mapPartitionsWithIndex</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#04%E3%80%81flatMap\"><span class=\"toc-text\">04、flatMap</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#05%E3%80%81glom\"><span class=\"toc-text\">05、glom</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#06%E3%80%81groupBy\"><span class=\"toc-text\">06、groupBy</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#07%E3%80%81filter\"><span class=\"toc-text\">07、filter</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#08%E3%80%81sample\"><span class=\"toc-text\">08、sample</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#09%E3%80%81distinct\"><span class=\"toc-text\">09、distinct</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#10%E3%80%81coalesce\"><span class=\"toc-text\">10、coalesce</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#11%E3%80%81repartition\"><span class=\"toc-text\">11、repartition</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#12%E3%80%81sortBy\"><span class=\"toc-text\">12、sortBy</span></a></li></ol></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#2-%E5%8F%8Cvalue%E7%B1%BB%E5%9E%8B\"><span class=\"toc-text\">2. 双value类型</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#01%E3%80%81intersection\"><span class=\"toc-text\">01、intersection</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#02%E3%80%81union\"><span class=\"toc-text\">02、union</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#03%E3%80%81subtract\"><span class=\"toc-text\">03、subtract</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#04%E3%80%81zip\"><span class=\"toc-text\">04、zip</span></a></li></ol></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#3-key-value%E7%B1%BB%E5%9E%8B\"><span class=\"toc-text\">3. key-value类型</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#01%E3%80%81partitionBy\"><span class=\"toc-text\">01、partitionBy</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#02%E3%80%81reduceByKey\"><span class=\"toc-text\">02、reduceByKey</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#03%E3%80%81groupByKey\"><span class=\"toc-text\">03、groupByKey</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#04%E3%80%81aggregateByKey\"><span class=\"toc-text\">04、aggregateByKey</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#05%E3%80%81foldByKey\"><span class=\"toc-text\">05、foldByKey</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#06%E3%80%81combineByKey\"><span class=\"toc-text\">06、combineByKey</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#07%E3%80%81sortByKey\"><span class=\"toc-text\">07、sortByKey</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#08%E3%80%81join\"><span class=\"toc-text\">08、join</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#09%E3%80%81leftOuterJoin\"><span class=\"toc-text\">09、leftOuterJoin</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#10%E3%80%81cogroup\"><span class=\"toc-text\">10、cogroup</span></a></li></ol></li></ol></li></ol></li></ol></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%B8%80%E4%BA%9B%E6%8A%A5%E9%94%99%E5%8F%8A%E8%A7%A3%E5%86%B3\"><span class=\"toc-text\">一些报错及解决</span></a></li></ol>","author":{"name":"Cencus","slug":"blog-author","avatar":"https://gitee.com/cencus/blog-image/raw/master/blogImage/1648381409561.jpg","link":"/","description":"stay hungry, stay foolish.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{},"next_post":{"title":"scala","uid":"a5d8f8aa75a85d4533d622d4e92bd3f1","slug":"scala","date":"2022-04-05T07:52:16.000Z","updated":"2022-04-09T11:04:15.302Z","comments":true,"path":"api/articles/scala.json","keywords":null,"cover":null,"text":"第1章 入门基于JVM，与Java关系密切 Java是一门先编译后解释的语言 Scala与java一样 特点：融合怪 面向对象 函数式编程 静态类型（类型提前声明指定）编程语言 多范式 结合了面对对象与函数式编程 .scala会被编译为java字节码.class，然后运行在JVM...","link":"","photos":[],"count_time":{"symbolsCount":"7.5k","symbolsTime":"7 mins."},"categories":[],"tags":[{"name":"语言，Scala，大数据","slug":"语言，Scala，大数据","count":1,"path":"api/tags/语言，Scala，大数据.json"}],"author":{"name":"Cencus","slug":"blog-author","avatar":"https://gitee.com/cencus/blog-image/raw/master/blogImage/1648381409561.jpg","link":"/","description":"stay hungry, stay foolish.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true}}