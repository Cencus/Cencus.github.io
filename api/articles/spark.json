{"title":"spark","uid":"e04902dcdb07e2ad1898c41f1efa8f40","slug":"spark","date":"2022-04-08T12:55:34.000Z","updated":"2022-04-14T09:53:45.147Z","comments":true,"path":"api/articles/spark.json","keywords":null,"cover":[],"content":"<h1 id=\"第3章-spark运行环境\"><a href=\"#第3章-spark运行环境\" class=\"headerlink\" title=\"第3章 spark运行环境\"></a>第3章 spark运行环境</h1><h1 id=\"3-1-local模式\"><a href=\"#3-1-local模式\" class=\"headerlink\" title=\"3.1 local模式\"></a>3.1 local模式</h1><h2 id=\"3-2-standalone模式\"><a href=\"#3-2-standalone模式\" class=\"headerlink\" title=\"3.2 standalone模式\"></a>3.2 standalone模式</h2><h2 id=\"3-3-yarn模式（公司常用）\"><a href=\"#3-3-yarn模式（公司常用）\" class=\"headerlink\" title=\"3.3 yarn模式（公司常用）\"></a>3.3 yarn模式（公司常用）</h2><h2 id=\"3-4-k8s-amp-Mesos模式\"><a href=\"#3-4-k8s-amp-Mesos模式\" class=\"headerlink\" title=\"3.4 k8s &amp; Mesos模式\"></a>3.4 k8s &amp; Mesos模式</h2><h2 id=\"3-5-windows模式\"><a href=\"#3-5-windows模式\" class=\"headerlink\" title=\"3.5 windows模式\"></a>3.5 windows模式</h2><h3 id=\"3-5-2-本地环境\"><a href=\"#3-5-2-本地环境\" class=\"headerlink\" title=\"3.5.2 本地环境\"></a>3.5.2 本地环境</h3><h1 id=\"第4章-spark运行架构\"><a href=\"#第4章-spark运行架构\" class=\"headerlink\" title=\"第4章 spark运行架构\"></a>第4章 spark运行架构</h1><p>Driver 驱动器节点，执行spark任务中的main方法，负责实际的代码执行，任务的调度与管理监控</p>\n<p>Executor：Worker中的一个JVM进程，负责运行具体的任务，任务的实际执行</p>\n<p>Master：资源的调度与分配类似于resourceManager</p>\n<p>Worker：</p>\n<p>AM：解耦Driver 计算 和RM 资源</p>\n<p>RDD的并行度&amp;分区</p>\n<p>makeRDD方法可以传递第二个参数，这个参数表示分区的数量</p>\n<p>第二个参数可以不传递，那么makeRDD会使用默认的数量</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token comment\">//数据如何分配到分区</span>\n\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n\n\n\n\n\n<h1 id=\"第5章-spark核心编程\"><a href=\"#第5章-spark核心编程\" class=\"headerlink\" title=\"第5章 spark核心编程\"></a>第5章 spark核心编程</h1><h2 id=\"5-1-RDD\"><a href=\"#5-1-RDD\" class=\"headerlink\" title=\"5.1 RDD\"></a>5.1 RDD</h2><h3 id=\"5-1-1-什么是RDD\"><a href=\"#5-1-1-什么是RDD\" class=\"headerlink\" title=\"5.1.1 什么是RDD\"></a>5.1.1 什么是RDD</h3><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p> Resilient Distributed Dataset：弹性分布式数据集</p>\n<p>是 Spark 中最基本的数据 处理模型</p>\n<p>代码中是一个<strong>抽象类</strong>，它代表一个<strong>弹性的</strong>、不可变、<strong>可分区</strong>、里面的元素<strong>可并行</strong>计算的集合。</p></blockquote>\n<p>简单一点就是<strong>数据+操作</strong></p>\n<p>逐个解释</p>\n<p>➢ 弹性</p>\n<ul>\n<li><p>存储的弹性：内存与磁盘的自动切换；</p>\n</li>\n<li><p>容错的弹性：数据丢失可以自动恢复； （有副本）</p>\n</li>\n<li><p>计算的弹性：计算出错重试机制； </p>\n</li>\n<li><p>分片的弹性：可根据需要重新分片。 （4个Executor可以改为4个分区）</p>\n</li>\n</ul>\n<p>➢ 分布式：数据存储在大数据集群不同节点上 </p>\n<p>➢ 数据集：RDD 封装了计算逻辑，并不<strong>保存数据</strong> （做完了就把数据发给下一步）</p>\n<p>➢ 数据抽象：RDD 是一个抽象类，需要子类具体实现 </p>\n<p>➢ 不可变：RDD 封装了计算逻辑，是<strong>不可以改变的</strong>，<strong>想要改变，只能产生新的 RDD</strong>，在 新的 RDD 里面封装计算逻辑 </p>\n<p>➢ 可分区、并行计算</p>\n<h3 id=\"5-1-2-核心属性\"><a href=\"#5-1-2-核心属性\" class=\"headerlink\" title=\"5.1.2 核心属性\"></a>5.1.2 核心属性</h3><ul>\n<li><p>分区列表</p>\n</li>\n<li><p>分区计算函数：每一个分区的计算方法</p>\n</li>\n<li><p>与其他RDD的依赖关系</p>\n</li>\n<li><p>分区器（可选）：数据放在哪个分区如我们有HashPartitioner</p>\n</li>\n<li><p>首选位置（可选）：将任务发给Executor时，发向哪一个Executor（就近原则，<strong>移动数据不如移动计算</strong>）</p>\n</li>\n</ul>\n<p>&#x2F;&#x2F; 完整 精简 准确 自己的理解</p>\n<h3 id=\"5-1-3-执行原理\"><a href=\"#5-1-3-执行原理\" class=\"headerlink\" title=\"5.1.3 执行原理\"></a>5.1.3 执行原理</h3><p>1、启动 Yarn 集群环境</p>\n<p><img src=\"https://gitee.com/cencus/blog-image/raw/master/blogImage/1649586103392.png\"></p>\n<p>2、Spark申请资源创建调度节点和计算节点（找人）</p>\n<p><img src=\"https://gitee.com/cencus/blog-image/raw/master/blogImage/1649586122389.png\"></p>\n<p>3、Spark 框架根据需求将计算逻辑根据分区划分成不同的任务（指定任务）</p>\n<p><img src=\"https://gitee.com/cencus/blog-image/raw/master/blogImage/1649586136386.png\"></p>\n<p>4、调度节点将任务根据计算节点状态发送到对应的计算节点进行计算（让员工执行任务）</p>\n<p><img src=\"https://gitee.com/cencus/blog-image/raw/master/blogImage/1649586149384.png\"></p>\n<h3 id=\"5-1-4-基础编程\"><a href=\"#5-1-4-基础编程\" class=\"headerlink\" title=\"5.1.4 基础编程\"></a>5.1.4 基础编程</h3><h4 id=\"5-1-4-1-RDD创建\"><a href=\"#5-1-4-1-RDD创建\" class=\"headerlink\" title=\"5.1.4.1 RDD创建\"></a>5.1.4.1 RDD创建</h4><p>1、从集合（内存）中创建RDD <em>常用</em></p>\n<p>两个方法<code>parallelize</code>和<code>makeRDD</code></p>\n<p>从底层来讲makeRDD就是parallelize只是对其进行了封装，更好记了</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">def</span> makeRDD<span class=\"token punctuation\">[</span>T<span class=\"token operator\">:</span> ClassTag<span class=\"token punctuation\">]</span><span class=\"token punctuation\">(</span>\n\tseq<span class=\"token operator\">:</span> Seq<span class=\"token punctuation\">[</span>T<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n\tnumSlices<span class=\"token operator\">:</span> <span class=\"token builtin\">Int</span> <span class=\"token operator\">=</span> defaultParallelism<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> RDD<span class=\"token punctuation\">[</span>T<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> withScope <span class=\"token punctuation\">&#123;</span>\n    parallelize<span class=\"token punctuation\">(</span>seq<span class=\"token punctuation\">,</span> numSlices<span class=\"token punctuation\">)</span>\n\t<span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n<p>2、从外部存储（文件）创建RDD <em>常用</em></p>\n<p><code>textFile(&quot;path&quot;)</code>方法</p>\n<p>支持的系统：本地FS，HDFS，HBase</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">val</span> fileRDD<span class=\"token operator\">:</span> RDD<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>textFile<span class=\"token punctuation\">(</span><span class=\"token string\">\"path\"</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">//所得是按照行分割的一个集合</span>\n\n<span class=\"token comment\">/*\n其中的path：\n* 目录(目录下的所有文件) 或者 具体文件\n* 通配符 textFile(\"datas/1*.txt\") 所有以1开头的.txt文件\n* 分布式存储路径： \"hdfs://hadoop102:8020/word.txt\"\n* wholeTextFiles() 以文件为单位读取数据，textFile是以行为单位，所得结果为一个turple (文件地址, 内容)\n*/</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n<p>3、从其他RDD创建</p>\n<p>…</p>\n<p>4、直接创建RDD</p>\n<p>…</p>\n<h4 id=\"5-1-4-2-RDD并行度与分区\"><a href=\"#5-1-4-2-RDD并行度与分区\" class=\"headerlink\" title=\"5.1.4.2 RDD并行度与分区\"></a>5.1.4.2 RDD并行度与分区</h4><p>并行度：能够并行计算的任务数量</p>\n<p><code>todo</code>：好像有些东西没有写上</p>\n<h4 id=\"5-1-4-3-RDD转换算子-重点\"><a href=\"#5-1-4-3-RDD转换算子-重点\" class=\"headerlink\" title=\"5.1.4.3 RDD转换算子(重点)\"></a>5.1.4.3 RDD转换算子(重点)</h4><h5 id=\"1-value类型\"><a href=\"#1-value类型\" class=\"headerlink\" title=\"1. value类型\"></a>1. value类型</h5><p>0、一些函数的解释</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\">collect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nforeach<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n\n\n\n\n\n<h6 id=\"01、map\"><a href=\"#01、map\" class=\"headerlink\" title=\"01、map\"></a>01、map</h6><p>函数签名：</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">def</span> map<span class=\"token punctuation\">[</span>U<span class=\"token operator\">:</span> ClassTag<span class=\"token punctuation\">]</span><span class=\"token punctuation\">(</span>f<span class=\"token operator\">:</span> T <span class=\"token keyword\">=></span> U<span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> RDD<span class=\"token punctuation\">[</span>U<span class=\"token punctuation\">]</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n<p>粗解：传入一个函数，输入是RDD，输入依然是RDD</p>\n<p>模板：</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\">rdd<span class=\"token punctuation\">.</span>map<span class=\"token punctuation\">(</span>\n\telem <span class=\"token keyword\">=></span><span class=\"token punctuation\">&#123;</span>\n        <span class=\"token comment\">//dosomthing</span>\n        <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n        newElem\n    <span class=\"token punctuation\">&#125;</span>\n    \n<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n\n\n<p>对于一个可遍历的rdd，逐个遍历并进行映射转换（就是操作啦）</p>\n<p>map方法，对于集合中的每个元素执行操作<br>    为什么老师说这里没有执行操作而是只是在逐层封装，只有collect才在执行操作，真的没有执行操作，<br>    那说明这些操作是被他们带上了，只有在collect的时候才执行 正确<br>    collect 返回rdd中的所有元素组成的数组，只能用于数据量小的时候，例如所有数据装入外存这种情况<br>     *&#x2F;</p>\n<p>例如想要对rdd里面的每一个元素乘2，就可以像下面这样写</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>atguigu<span class=\"token punctuation\">.</span>bigdata<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>core<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>transform</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span></span>RDD\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">&#123;</span>SparkConf<span class=\"token punctuation\">,</span> SparkContext<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token keyword\">object</span> Spark01_RDD_Operator_Transform <span class=\"token punctuation\">&#123;</span>\n  <span class=\"token keyword\">def</span> main<span class=\"token punctuation\">(</span>args<span class=\"token operator\">:</span> Array<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token keyword\">val</span> sparkConf <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setMaster<span class=\"token punctuation\">(</span><span class=\"token string\">\"local[*]\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"Operator\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">val</span> sc <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkContext<span class=\"token punctuation\">(</span>sparkConf<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//TODO 算子-map</span>\n    <span class=\"token comment\">//需求：将[1,2,3,4]变为[2,4,6,8]</span>\n    <span class=\"token keyword\">val</span> rdd <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">val</span> mapRDD<span class=\"token operator\">:</span> RDD<span class=\"token punctuation\">[</span><span class=\"token builtin\">Int</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> rdd<span class=\"token punctuation\">.</span>map<span class=\"token punctuation\">(</span>_ <span class=\"token operator\">*</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n\n    mapRDD<span class=\"token punctuation\">.</span>collect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>foreach<span class=\"token punctuation\">(</span>println<span class=\"token punctuation\">)</span>\n\n    sc<span class=\"token punctuation\">.</span>stop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n<p>rdd的计算是一个分区内的数据是一个一个的数据执行我们的逻辑，只有前面的一个数据逻辑执行完毕后，才会执行下一个数据，<br>分区内数据的执行是有序的</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>atguigu<span class=\"token punctuation\">.</span>bigdata<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>core<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>transform</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span></span>RDD\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">&#123;</span>SparkConf<span class=\"token punctuation\">,</span> SparkContext<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token keyword\">object</span> Spark01_RDD_Operator_Transform_Par <span class=\"token punctuation\">&#123;</span>\n  <span class=\"token keyword\">def</span> main<span class=\"token punctuation\">(</span>args<span class=\"token operator\">:</span> Array<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token keyword\">val</span> sparkConf <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setMaster<span class=\"token punctuation\">(</span><span class=\"token string\">\"local[*]\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"Operator\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">val</span> sc <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkContext<span class=\"token punctuation\">(</span>sparkConf<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//TODO 算子-map</span>\n    <span class=\"token keyword\">val</span> rdd <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">val</span> mapRDD <span class=\"token operator\">=</span> rdd<span class=\"token punctuation\">.</span>map<span class=\"token punctuation\">(</span>\n      num <span class=\"token keyword\">=></span> <span class=\"token punctuation\">&#123;</span>\n        println<span class=\"token punctuation\">(</span><span class=\"token string\">\">>>>>>> \"</span> <span class=\"token operator\">+</span> num<span class=\"token punctuation\">)</span>\n        num\n      <span class=\"token punctuation\">&#125;</span>\n    <span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">val</span> mapRDD1 <span class=\"token operator\">=</span> mapRDD<span class=\"token punctuation\">.</span>map<span class=\"token punctuation\">(</span>\n      num <span class=\"token keyword\">=></span> <span class=\"token punctuation\">&#123;</span>\n        println<span class=\"token punctuation\">(</span><span class=\"token string\">\"####### \"</span> <span class=\"token operator\">+</span> num<span class=\"token punctuation\">)</span>\n        num\n      <span class=\"token punctuation\">&#125;</span>\n    <span class=\"token punctuation\">)</span>\n    mapRDD1<span class=\"token punctuation\">.</span>collect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    sc<span class=\"token punctuation\">.</span>stop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token punctuation\">&#125;</span>\n\n\n<span class=\"token comment\">/*\n分区1：[1,2]\n分区2: [3,4]\n分区各自独立，可以保证，2不可能再1前面，4不能再3前面\n不同分区之间数据的执行是无序的\n>>>>>>> 3\n>>>>>>> 1\n####### 1\n####### 3\n>>>>>>> 2\n####### 2\n>>>>>>> 4\n####### 4\n\n\n\nrdd的计算是一个分区内的数据是一个一个的数据执行我们的逻辑，只有前面的一个数据逻辑执行完毕后，才会执行下一个数据，\n分区内数据的执行是有序的\nrdd.map(1) => mapRDD.map(1)\nrdd.map(2) => mapRDD.map(2)\nrdd.map(3) => mapRDD.map(3)\nrdd.map(4) => mapRDD.map(4)\n>>>>>>> 1\n####### 1\n>>>>>>> 2\n####### 2\n>>>>>>> 3\n####### 3\n>>>>>>> 4\n####### 4\n\n\n\n */</span>\n\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n<h6 id=\"02、mapPartitions\"><a href=\"#02、mapPartitions\" class=\"headerlink\" title=\"02、mapPartitions\"></a>02、mapPartitions</h6><p>函数签名：</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">def</span> mapPartitions<span class=\"token punctuation\">[</span>U<span class=\"token operator\">:</span> ClassTag<span class=\"token punctuation\">]</span><span class=\"token punctuation\">(</span>\n \tf<span class=\"token operator\">:</span> Iterator<span class=\"token punctuation\">[</span>T<span class=\"token punctuation\">]</span> <span class=\"token keyword\">=></span> Iterator<span class=\"token punctuation\">[</span>U<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n \tpreservesPartitioning<span class=\"token operator\">:</span> <span class=\"token builtin\">Boolean</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">false</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> RDD<span class=\"token punctuation\">[</span>U<span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>粗解：传入一个函数：函数的传入类型为迭代类型，返回类型为迭代器</p>\n<p>使用模板：</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\">rdd<span class=\"token punctuation\">.</span>mapPartitions<span class=\"token punctuation\">(</span>\n\titer <span class=\"token keyword\">=></span> <span class=\"token punctuation\">&#123;</span>\n        <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span>\n        newIter <span class=\"token comment\">// List().iterator</span>\n    <span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>我的一些理解：</p>\n<p>将待处理的数据<strong>以分区为单位</strong>发送到计算节点进行处理，这里的处理是指可以进行任意的处 理，哪怕是过滤数据。</p>\n<p>mappartition方法到底在干嘛<br> rdd是一个上述的那种数据集，将rdd以分区为单位进行处理，完了把处理好的返回</p>\n<p>下面是一个使用案例</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>atguigu<span class=\"token punctuation\">.</span>bigdata<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>core<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>transform</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span></span>RDD\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">&#123;</span>SparkConf<span class=\"token punctuation\">,</span> SparkContext<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token keyword\">object</span> Spark02_RDD_Operator_Transform <span class=\"token punctuation\">&#123;</span>\n  <span class=\"token keyword\">def</span> main<span class=\"token punctuation\">(</span>args<span class=\"token operator\">:</span> Array<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token keyword\">val</span> sparkConf <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setMaster<span class=\"token punctuation\">(</span><span class=\"token string\">\"local[*]\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"Operator\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">val</span> sc <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkContext<span class=\"token punctuation\">(</span>sparkConf<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//TODO 算子-map</span>\n    <span class=\"token keyword\">val</span> rdd <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//高性能做法，将一个分区全部拿到以后再做操作，而不是一个一个做操作</span>\n    <span class=\"token keyword\">val</span> mapRDD <span class=\"token operator\">=</span> rdd<span class=\"token punctuation\">.</span>mapPartitions<span class=\"token punctuation\">(</span>\n      iter <span class=\"token keyword\">=></span> <span class=\"token punctuation\">&#123;</span>\n        println<span class=\"token punctuation\">(</span><span class=\"token string\">\">>>>>>>>>>>>>>>\"</span><span class=\"token punctuation\">)</span>\n        iter<span class=\"token punctuation\">.</span>map<span class=\"token punctuation\">(</span>_ <span class=\"token operator\">*</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n      <span class=\"token punctuation\">&#125;</span>\n    <span class=\"token punctuation\">)</span>\n\n    mapRDD<span class=\"token punctuation\">.</span>collect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>foreach<span class=\"token punctuation\">(</span>println<span class=\"token punctuation\">)</span>\n\n    sc<span class=\"token punctuation\">.</span>stop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token punctuation\">&#125;</span>\n\n\n<span class=\"token comment\">/*\nmappartitions类似缓冲\n说明执行了两次，因为有两个分区，一次把一个分区拿过来，放在内存计算，类似于批处理，\n>>>>>>>>>>>>>>>\n>>>>>>>>>>>>>>>\n2\n4\n6\n8\n但是不好的地方：\n* 当一个分区没有计算完成，比如说 10000条数据计算了999条，这999条不会释放，因为存在对象的引用\n* 在内存较小，数据量较大的场景下容易出现内存移除，这种情况下还是用map\n */</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>案例返回每个数据分区的最大值</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>atguigu<span class=\"token punctuation\">.</span>bigdata<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>core<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>transform</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">&#123;</span>SparkConf<span class=\"token punctuation\">,</span> SparkContext<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token keyword\">object</span> Spark02_RDD_Operator_Transform_Test <span class=\"token punctuation\">&#123;</span>\n  <span class=\"token keyword\">def</span> main<span class=\"token punctuation\">(</span>args<span class=\"token operator\">:</span> Array<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token keyword\">val</span> sparkConf <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setMaster<span class=\"token punctuation\">(</span><span class=\"token string\">\"local[*]\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"Operator\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">val</span> sc <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkContext<span class=\"token punctuation\">(</span>sparkConf<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//TODO 算子-map</span>\n    <span class=\"token keyword\">val</span> rdd <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n      \n    <span class=\"token comment\">//需求获取每个分区的最大值</span>\n    <span class=\"token keyword\">val</span> mapRDD <span class=\"token operator\">=</span> rdd<span class=\"token punctuation\">.</span>mapPartitions<span class=\"token punctuation\">(</span>\n      iter <span class=\"token keyword\">=></span> <span class=\"token punctuation\">&#123;</span>\n        List<span class=\"token punctuation\">(</span>iter<span class=\"token punctuation\">.</span>max<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>iterator\n      <span class=\"token punctuation\">&#125;</span>\n    <span class=\"token punctuation\">)</span>\n\n    mapRDD<span class=\"token punctuation\">.</span>collect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>foreach<span class=\"token punctuation\">(</span>println<span class=\"token punctuation\">)</span>\n      \n    sc<span class=\"token punctuation\">.</span>stop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n<p>map与mapPartitions的区别</p>\n<table>\n<thead>\n<tr>\n<th>角度</th>\n<th>map</th>\n<th>mapPartitions</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>数据处理角度</td>\n<td>Map 算子是分区内一个数据一个数据的执行，类似于<strong>串行操作</strong></td>\n<td>mapPartitions 算子 是以分区为单位进行<strong>批处理操作</strong></td>\n</tr>\n<tr>\n<td>功能的角度</td>\n<td>Map 算子主要目的将数据源中的数据进行<strong>转换和改变</strong>。但是不会<strong>减少或增多数据</strong></td>\n<td>MapPartitions 算子需要传递一个迭代器，返回一个迭代器，<strong>没有要求的元素的个数保持不变， 所以可以增加或减少数据</strong></td>\n</tr>\n<tr>\n<td>性能的角度</td>\n<td>Map 算子因为类似于串行操作，所以性能比较<strong>低</strong></td>\n<td>mapPartitions 算子类似于批处 理，所以性能较<strong>高</strong><br />但是 mapPartitions 算子会长时间占用内存，那么这样会导致内存可能 不够用，出现内存溢出的错误。所以<strong>在内存有限的情况下，不推荐使用</strong>。使用 map 操作替代</td>\n</tr>\n</tbody></table>\n<h6 id=\"03、mapPartitionsWithIndex\"><a href=\"#03、mapPartitionsWithIndex\" class=\"headerlink\" title=\"03、mapPartitionsWithIndex\"></a>03、mapPartitionsWithIndex</h6><h6 id=\"04、flatMap\"><a href=\"#04、flatMap\" class=\"headerlink\" title=\"04、flatMap\"></a>04、flatMap</h6><p>扁平化处理，是不是听不懂，像这种list里面嵌套了list的结构，就可以用这种方式去做处理把<code>List(List(1,2), List(3,4))</code>变成 <code>List(1,2,3,4)</code></p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">val</span> rdd <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> List<span class=\"token punctuation\">(</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">//</span>\n\nrdd<span class=\"token punctuation\">.</span>flatMap<span class=\"token punctuation\">(</span>\n list <span class=\"token keyword\">=></span> <span class=\"token punctuation\">&#123;</span>\n     <span class=\"token comment\">//do something</span>\n     new_list\n <span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n\n\n<h6 id=\"05、glom\"><a href=\"#05、glom\" class=\"headerlink\" title=\"05、glom\"></a>05、glom</h6><h6 id=\"06、groupBy\"><a href=\"#06、groupBy\" class=\"headerlink\" title=\"06、groupBy\"></a>06、groupBy</h6><h6 id=\"07、filter\"><a href=\"#07、filter\" class=\"headerlink\" title=\"07、filter\"></a>07、filter</h6><h6 id=\"08、sample\"><a href=\"#08、sample\" class=\"headerlink\" title=\"08、sample\"></a>08、sample</h6><h6 id=\"09、distinct\"><a href=\"#09、distinct\" class=\"headerlink\" title=\"09、distinct\"></a>09、distinct</h6><h6 id=\"10、coalesce\"><a href=\"#10、coalesce\" class=\"headerlink\" title=\"10、coalesce\"></a>10、coalesce</h6><h6 id=\"11、repartition\"><a href=\"#11、repartition\" class=\"headerlink\" title=\"11、repartition\"></a>11、repartition</h6><h6 id=\"12、sortBy\"><a href=\"#12、sortBy\" class=\"headerlink\" title=\"12、sortBy\"></a>12、sortBy</h6><h5 id=\"2-双value类型\"><a href=\"#2-双value类型\" class=\"headerlink\" title=\"2. 双value类型\"></a>2. 双value类型</h5><h6 id=\"01、intersection\"><a href=\"#01、intersection\" class=\"headerlink\" title=\"01、intersection\"></a>01、intersection</h6><h6 id=\"02、union\"><a href=\"#02、union\" class=\"headerlink\" title=\"02、union\"></a>02、union</h6><h6 id=\"03、subtract\"><a href=\"#03、subtract\" class=\"headerlink\" title=\"03、subtract\"></a>03、subtract</h6><h6 id=\"04、zip\"><a href=\"#04、zip\" class=\"headerlink\" title=\"04、zip\"></a>04、zip</h6><h5 id=\"3-key-value类型\"><a href=\"#3-key-value类型\" class=\"headerlink\" title=\"3. key-value类型\"></a>3. key-value类型</h5><h6 id=\"01、partitionBy\"><a href=\"#01、partitionBy\" class=\"headerlink\" title=\"01、partitionBy\"></a>01、partitionBy</h6><pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>atguigu<span class=\"token punctuation\">.</span>bigdata<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>core<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>transform</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span></span>RDD\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">&#123;</span>HashPartitioner<span class=\"token punctuation\">,</span> SparkConf<span class=\"token punctuation\">,</span> SparkContext<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token keyword\">object</span> Spark14_RDD_Operator_Transform <span class=\"token punctuation\">&#123;</span>\n  <span class=\"token keyword\">def</span> main<span class=\"token punctuation\">(</span>args<span class=\"token operator\">:</span> Array<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token keyword\">val</span> sparkConf <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setMaster<span class=\"token punctuation\">(</span><span class=\"token string\">\"local[*]\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"Operator\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">val</span> sc <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkContext<span class=\"token punctuation\">(</span>sparkConf<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//TODO Key-Value类型</span>\n\n    <span class=\"token keyword\">val</span> rdd <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">val</span> mapRDD<span class=\"token operator\">:</span> RDD<span class=\"token punctuation\">[</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">Int</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">Int</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> rdd<span class=\"token punctuation\">.</span>map<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>_<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">//把数值变成了turple类型，对偶元组可以使用了</span>\n\n    <span class=\"token comment\">//该方法不是rdd的是pairrddfunctions方法</span>\n    <span class=\"token comment\">//RDD[T]中T的写法就直接写里面的元素的类型</span>\n    <span class=\"token comment\">//scala中的隐式转换，查找转换规则，可以简单理解为二次编译</span>\n\n    <span class=\"token comment\">/*\n    implicit def rddToPairRDDFunctions[K, V](rdd: RDD[(K, V)])\n    (implicit kt: ClassTag[K], vt: ClassTag[V], ord: Ordering[K] = null): PairRDDFunctions[K, V] = &#123;\n    new PairRDDFunctions(rdd)\n  &#125;\n  隐式函数，rdd转换为PairRDDFunctions 遵循了OCP开发原则开放封闭原则（OCP，Open Closed Principle）是所有 面向对象 原则的核心。 软件设计本身所追求的目标就是**封装变化、降低耦合**，而开放封闭原则正是对这一目标的最直接体现。 其他的设计原则，很多时候是为实现这一目标服务的，例如以Liskov替换原则实现最佳的、正确的继承层次，就能保证不会违反开放封闭原则。 软件实体应该是可扩展，而不可修改的。\n\n     */</span>\n    <span class=\"token comment\">//改变数据所在的分区</span>\n    mapRDD<span class=\"token punctuation\">.</span>partitionBy<span class=\"token punctuation\">(</span><span class=\"token keyword\">new</span> HashPartitioner<span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n      <span class=\"token punctuation\">.</span>saveAsTextFile<span class=\"token punctuation\">(</span><span class=\"token string\">\"output\"</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//ctrl + h查看当前所在类的实现类</span>\n\n\n\n\n    <span class=\"token comment\">//打开之后24一个分区，13一个分区，为什么呢？</span>\n    <span class=\"token comment\">/*\n    def getPartition(key: Any): Int = key match &#123;\n    case null => 0\n    case _ => Utils.nonNegativeMod(key.hashCode, numPartitions)\n  &#125;\n  def nonNegativeMod(x: Int, mod: Int): Int = &#123;\n    val rawMod = x % mod\n    rawMod + (if (rawMod &lt; 0) mod else 0)\n  &#125;\n     */</span>\n\n\n\n    sc<span class=\"token punctuation\">.</span>stop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<h6 id=\"02、reduceByKey\"><a href=\"#02、reduceByKey\" class=\"headerlink\" title=\"02、reduceByKey\"></a>02、reduceByKey</h6><p>粗解：</p>\n<p>相同的key分在同一个组，对其value做两两聚合</p>\n<p>如下述情况，聚合方式写在了注释中</p>\n<p>格式：</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token comment\">//一般形式</span>\nrdd<span class=\"token punctuation\">.</span>reduceByKey<span class=\"token punctuation\">(</span>\n    <span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span> <span class=\"token keyword\">=></span> <span class=\"token punctuation\">&#123;</span>\n        <span class=\"token comment\">//将xy聚合的操作，如x + y</span>\n        x <span class=\"token operator\">+</span> y\n    <span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">)</span>\n<span class=\"token comment\">//简写只需要写两个数的操作方式</span>\nrdd<span class=\"token punctuation\">.</span>reduceByKey<span class=\"token punctuation\">(</span>_<span class=\"token operator\">+</span>_<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>atguigu<span class=\"token punctuation\">.</span>bigdata<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>core<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>transform</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span></span>RDD\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">&#123;</span>HashPartitioner<span class=\"token punctuation\">,</span> SparkConf<span class=\"token punctuation\">,</span> SparkContext<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token keyword\">object</span> Spark15_RDD_Operator_Transform <span class=\"token punctuation\">&#123;</span>\n  <span class=\"token keyword\">def</span> main<span class=\"token punctuation\">(</span>args<span class=\"token operator\">:</span> Array<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token keyword\">val</span> sparkConf <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setMaster<span class=\"token punctuation\">(</span><span class=\"token string\">\"local[*]\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"Operator\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">val</span> sc <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkContext<span class=\"token punctuation\">(</span>sparkConf<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//TODO Key-Value类型</span>\n    <span class=\"token keyword\">val</span> rdd <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span>\n      <span class=\"token punctuation\">(</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"b\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//需求：相同的key分在同一个组，对其value做聚合</span>\n    <span class=\"token comment\">//相同的key的数据进行value的聚合操作 又涉及到了分组的概念</span>\n    <span class=\"token comment\">//scala中聚合操作一般都是两两聚合，spark也是</span>\n    <span class=\"token comment\">//[1,2,3]</span>\n    <span class=\"token comment\">//[3,3]</span>\n    <span class=\"token comment\">//[6]</span>\n    <span class=\"token comment\">//reduceByKey中，如果key的数据只有一个，是不会参与运算的</span>\n\n    <span class=\"token comment\">//底层用了hashpartition</span>\n    <span class=\"token keyword\">val</span> reduceRDD <span class=\"token operator\">=</span> rdd<span class=\"token punctuation\">.</span>reduceByKey<span class=\"token punctuation\">(</span>\n      <span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">)</span> <span class=\"token keyword\">=></span> <span class=\"token punctuation\">&#123;</span>\n        println<span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token id function\">s</span><span class=\"token string\">\"x=</span><span class=\"token interpolation\"><span class=\"token punctuation\">$</span><span class=\"token expression\">x</span></span><span class=\"token string\">,y=</span><span class=\"token interpolation\"><span class=\"token punctuation\">$</span><span class=\"token expression\">y</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\n        x <span class=\"token operator\">+</span> y\n      <span class=\"token punctuation\">&#125;</span>\n    <span class=\"token punctuation\">)</span>\n\n    reduceRDD<span class=\"token punctuation\">.</span>collect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>foreach<span class=\"token punctuation\">(</span>println<span class=\"token punctuation\">)</span>\n\n\n    sc<span class=\"token punctuation\">.</span>stop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<h6 id=\"03、groupByKey\"><a href=\"#03、groupByKey\" class=\"headerlink\" title=\"03、groupByKey\"></a>03、groupByKey</h6><p>将数据源中相同key的数据分在一个组中，形成一个对偶元组 <code>(key, 相同key的value的可迭代集合)</code></p>\n<p>格式：</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\">rdd<span class=\"token punctuation\">.</span>groupByKey<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token comment\">//直接按照key来分组，底层用到了HashPartitioner</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n\n\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>atguigu<span class=\"token punctuation\">.</span>bigdata<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>core<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>transform</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">&#123;</span>SparkConf<span class=\"token punctuation\">,</span> SparkContext<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token keyword\">object</span> Spark16_RDD_Operator_Transform <span class=\"token punctuation\">&#123;</span>\n  <span class=\"token keyword\">def</span> main<span class=\"token punctuation\">(</span>args<span class=\"token operator\">:</span> Array<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token keyword\">val</span> sparkConf <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setMaster<span class=\"token punctuation\">(</span><span class=\"token string\">\"local[*]\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"Operator\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">val</span> sc <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkContext<span class=\"token punctuation\">(</span>sparkConf<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//TODO Key-Value类型</span>\n    <span class=\"token keyword\">val</span> rdd <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span>\n      <span class=\"token punctuation\">(</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"b\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//将数据源中相同key的数据分在一个组中，形成一个对偶元组</span>\n    <span class=\"token comment\">//(key, 相同key的value的可迭代集合)</span>\n    <span class=\"token comment\">//(a,CompactBuffer(1, 2, 3))</span>\n    <span class=\"token comment\">//(b,CompactBuffer(4))</span>\n\n    <span class=\"token keyword\">val</span> groupRDD <span class=\"token operator\">=</span> rdd<span class=\"token punctuation\">.</span>groupByKey<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n\n    <span class=\"token comment\">//groupBy</span>\n    <span class=\"token comment\">//</span>\n    <span class=\"token comment\">//val groupRDD = rdd.groupBy(_._1)</span>\n\n    groupRDD<span class=\"token punctuation\">.</span>collect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>foreach<span class=\"token punctuation\">(</span>println<span class=\"token punctuation\">)</span>\n\n    sc<span class=\"token punctuation\">.</span>stop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token punctuation\">&#125;</span>\n<span class=\"token comment\">/*\n使用什么分组不确定，groupby要传进去，groupbykey不用\n得到的结果而言：一个是(key,value的集合)\n一个是(key,(key,value)的集合)\n */</span>\n\n<span class=\"token comment\">/*\ngroupByKey会导致数据打乱重组，涉及shuffle\nspark中的shuffle操作必须要落盘处理，不能在内存中数据等待，否则会越积越多，导致内存溢出\n落盘涉及磁盘I/O，会影响性能，所以shuffle的性能很低\n */</span>\n\n<span class=\"token comment\">/*\nreduceByKey支持分区内预聚合功能，可以有效减少shuffle时的落盘量，提高性能\n */</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>与groupBy的区别</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>atguigu<span class=\"token punctuation\">.</span>bigdata<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>core<span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span>operator<span class=\"token punctuation\">.</span>transform</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">&#123;</span>SparkConf<span class=\"token punctuation\">,</span> SparkContext<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token keyword\">object</span> Spark16_RDD_Operator_Transform <span class=\"token punctuation\">&#123;</span>\n  <span class=\"token keyword\">def</span> main<span class=\"token punctuation\">(</span>args<span class=\"token operator\">:</span> Array<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token keyword\">val</span> sparkConf <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setMaster<span class=\"token punctuation\">(</span><span class=\"token string\">\"local[*]\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"Operator\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">val</span> sc <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkContext<span class=\"token punctuation\">(</span>sparkConf<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//TODO Key-Value类型</span>\n    <span class=\"token keyword\">val</span> rdd <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span>\n      <span class=\"token punctuation\">(</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"b\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n      \n    <span class=\"token keyword\">val</span> groupRDD <span class=\"token operator\">=</span> rdd<span class=\"token punctuation\">.</span>groupBy<span class=\"token punctuation\">(</span>_<span class=\"token punctuation\">.</span>_1<span class=\"token punctuation\">)</span>\n\n    groupRDD<span class=\"token punctuation\">.</span>collect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>foreach<span class=\"token punctuation\">(</span>println<span class=\"token punctuation\">)</span>\n\n    sc<span class=\"token punctuation\">.</span>stop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token punctuation\">&#125;</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<table>\n<thead>\n<tr>\n<th>角度</th>\n<th>groupBy</th>\n<th>groupByKey</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>分组方式</td>\n<td>传参</td>\n<td>不用</td>\n</tr>\n<tr>\n<td>结果</td>\n<td>(key,value的集合)</td>\n<td>(key,(key,value)的集合)</td>\n</tr>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<p>面试题：reduceByKey和groupByKey的区别</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><ul>\n<li>spark中的shuffle操作必须要<strong>落盘处理</strong>，不能在内存中数据等待，否则会越积越多，导致内存溢出<br>落盘涉及磁盘I&#x2F;O，会影响性能，所以<strong>shuffle的性能很低</strong></li>\n<li>reduceByKey支持<strong>分区内预聚合</strong>功能，可以有效减少shuffle时的落盘量，<strong>提高性能</strong></li>\n</ul></blockquote>\n<table>\n<thead>\n<tr>\n<th>角度</th>\n<th>reduceByKey</th>\n<th>groupByKey</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>从 shuffle 的角度</td>\n<td><strong>reduceByKey 和 groupByKey 都存在 shuffle 的操作</strong>，但是 reduceByKey 可以在 shuffle 前对分区内相同 key 的数据进行<strong>预聚合</strong>（combine）功能，这样会减少落盘的 数据量，reduceByKey <strong>性能比较高</strong>。</td>\n<td>而 groupByKey 只是进行分组，不存在数据量减少的问题</td>\n</tr>\n<tr>\n<td>从功能的角度</td>\n<td>reduceByKey 其实包含分组和聚合的功能<br />所以在<strong>分组聚合</strong>的场合下，推荐使用 reduceByKey</td>\n<td>GroupByKey 只能分组，不能聚合<br />如果<strong>仅仅是分组而不需要聚合</strong>那么还是只能使用 groupByKey</td>\n</tr>\n</tbody></table>\n<h6 id=\"04、aggregateByKey\"><a href=\"#04、aggregateByKey\" class=\"headerlink\" title=\"04、aggregateByKey\"></a>04、aggregateByKey</h6><h6 id=\"05、foldByKey\"><a href=\"#05、foldByKey\" class=\"headerlink\" title=\"05、foldByKey\"></a>05、foldByKey</h6><h6 id=\"06、combineByKey\"><a href=\"#06、combineByKey\" class=\"headerlink\" title=\"06、combineByKey\"></a>06、combineByKey</h6><h6 id=\"07、sortByKey\"><a href=\"#07、sortByKey\" class=\"headerlink\" title=\"07、sortByKey\"></a>07、sortByKey</h6><h6 id=\"08、join\"><a href=\"#08、join\" class=\"headerlink\" title=\"08、join\"></a>08、join</h6><h6 id=\"09、leftOuterJoin\"><a href=\"#09、leftOuterJoin\" class=\"headerlink\" title=\"09、leftOuterJoin\"></a>09、leftOuterJoin</h6><h6 id=\"10、cogroup\"><a href=\"#10、cogroup\" class=\"headerlink\" title=\"10、cogroup\"></a>10、cogroup</h6><h6 id=\"11、mapValues\"><a href=\"#11、mapValues\" class=\"headerlink\" title=\"11、mapValues\"></a>11、mapValues</h6><p>遍历具有kv结构的数据的所有value，而不会改变key的值，并且会待在原来的分区</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\">rdd1<span class=\"token punctuation\">.</span>mapValues<span class=\"token punctuation\">(</span>value <span class=\"token keyword\">=></span> println<span class=\"token punctuation\">(</span>value<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n\n\n\n\n<h4 id=\"5-1-4-4-案例实操\"><a href=\"#5-1-4-4-案例实操\" class=\"headerlink\" title=\"5.1.4.4 案例实操\"></a>5.1.4.4 案例实操</h4><h4 id=\"5-1-4-5-行动算子\"><a href=\"#5-1-4-5-行动算子\" class=\"headerlink\" title=\"5.1.4.5 行动算子\"></a>5.1.4.5 行动算子</h4><h5 id=\"1、reduce\"><a href=\"#1、reduce\" class=\"headerlink\" title=\"1、reduce\"></a>1、reduce</h5><h5 id=\"2、collect\"><a href=\"#2、collect\" class=\"headerlink\" title=\"2、collect\"></a>2、collect</h5><h5 id=\"3、count\"><a href=\"#3、count\" class=\"headerlink\" title=\"3、count\"></a>3、count</h5><h5 id=\"4、first\"><a href=\"#4、first\" class=\"headerlink\" title=\"4、first\"></a>4、first</h5><h5 id=\"5、take\"><a href=\"#5、take\" class=\"headerlink\" title=\"5、take\"></a>5、take</h5><h5 id=\"6、takeOrderd\"><a href=\"#6、takeOrderd\" class=\"headerlink\" title=\"6、takeOrderd\"></a>6、takeOrderd</h5><h5 id=\"7、aggregate\"><a href=\"#7、aggregate\" class=\"headerlink\" title=\"7、aggregate\"></a>7、aggregate</h5><h5 id=\"8、fold\"><a href=\"#8、fold\" class=\"headerlink\" title=\"8、fold\"></a>8、fold</h5><h5 id=\"9、countByKey\"><a href=\"#9、countByKey\" class=\"headerlink\" title=\"9、countByKey\"></a>9、countByKey</h5><h5 id=\"10、save相关算子\"><a href=\"#10、save相关算子\" class=\"headerlink\" title=\"10、save相关算子\"></a>10、save相关算子</h5><h5 id=\"11、foreach\"><a href=\"#11、foreach\" class=\"headerlink\" title=\"11、foreach\"></a>11、foreach</h5><h4 id=\"5-1-4-6-RDD序列化\"><a href=\"#5-1-4-6-RDD序列化\" class=\"headerlink\" title=\"5.1.4.6 RDD序列化\"></a>5.1.4.6 RDD序列化</h4><p>1、闭包检查：从计算的角度, <strong>算子以外的代码都是在 Driver 端执行, 算子里面的代码都是在 Executor 端执行</strong>。那么在 scala 的函数式编程中，就会导致<strong>算子内经常会用到算子外的数据</strong>，这样就 形成了闭包的效果，如果使用的算子外的数据无法序列化，就意味着无法传值给 Executor 端执行（需要网络传输），就会发生错误，所以需要在执行任务计算前，<strong>检测闭包内的对象是否可以进行序列化</strong>，这个操作我们称之为闭包检测。<span style=\"color:blue\">Scala2.12 版本后闭包编译方式发生了改变 </span></p>\n<p>2、序列化方法和属性从计算的角度, <strong>算子以外的代码都是在 Driver 端执行, 算子里面的代码都是在 Executor 端执行</strong>，看如下代码：</p>\n<p>3、Kryo 序列化框架</p>\n<p>参考地址: <a href=\"https://github.com/EsotericSoftware/kryo\">https://github.com/EsotericSoftware/kryo</a></p>\n<p>更轻量，spark底层支持，不需要具体指定，但是可以</p>\n<p>注意：即使使用 Kryo 序列化，也要继承 Serializable 接口。</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">object</span> serializable_Kryo <span class=\"token punctuation\">&#123;</span>\n <span class=\"token keyword\">def</span> main<span class=\"token punctuation\">(</span>args<span class=\"token operator\">:</span> Array<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n <span class=\"token keyword\">val</span> conf<span class=\"token operator\">:</span> SparkConf <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"SerDemo\"</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">.</span>setMaster<span class=\"token punctuation\">(</span><span class=\"token string\">\"local[*]\"</span><span class=\"token punctuation\">)</span>\n <span class=\"token comment\">// 替换默认的序列化机制</span>\n <span class=\"token punctuation\">.</span>set<span class=\"token punctuation\">(</span><span class=\"token string\">\"spark.serializer\"</span><span class=\"token punctuation\">,</span> \n<span class=\"token string\">\"org.apache.spark.serializer.KryoSerializer\"</span><span class=\"token punctuation\">)</span> \n <span class=\"token comment\">// 注册需要使用 kryo 序列化的自定义类</span>\n <span class=\"token punctuation\">.</span>registerKryoClasses<span class=\"token punctuation\">(</span>Array<span class=\"token punctuation\">(</span>classOf<span class=\"token punctuation\">[</span>Searcher<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token comment\">//Search是类名</span>\n     \n <span class=\"token keyword\">val</span> sc <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkContext<span class=\"token punctuation\">(</span>conf<span class=\"token punctuation\">)</span>\n <span class=\"token keyword\">val</span> rdd<span class=\"token operator\">:</span> RDD<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>Array<span class=\"token punctuation\">(</span><span class=\"token string\">\"hello world\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"hello atguigu\"</span><span class=\"token punctuation\">,</span> \n<span class=\"token string\">\"atguigu\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"hahah\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n <span class=\"token keyword\">val</span> searcher <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> Searcher<span class=\"token punctuation\">(</span><span class=\"token string\">\"hello\"</span><span class=\"token punctuation\">)</span>\n <span class=\"token keyword\">val</span> result<span class=\"token operator\">:</span> RDD<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> searcher<span class=\"token punctuation\">.</span>getMatchedRDD1<span class=\"token punctuation\">(</span>rdd<span class=\"token punctuation\">)</span>\n result<span class=\"token punctuation\">.</span>collect<span class=\"token punctuation\">.</span>foreach<span class=\"token punctuation\">(</span>println<span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">&#125;</span>\n<span class=\"token keyword\">case</span> <span class=\"token keyword\">class</span> Searcher<span class=\"token punctuation\">(</span><span class=\"token keyword\">val</span> query<span class=\"token operator\">:</span> <span class=\"token builtin\">String</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n <span class=\"token keyword\">def</span> isMatch<span class=\"token punctuation\">(</span>s<span class=\"token operator\">:</span> <span class=\"token builtin\">String</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n s<span class=\"token punctuation\">.</span>contains<span class=\"token punctuation\">(</span>query<span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">&#125;</span>\n <span class=\"token keyword\">def</span> getMatchedRDD1<span class=\"token punctuation\">(</span>rdd<span class=\"token operator\">:</span> RDD<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n rdd<span class=\"token punctuation\">.</span>filter<span class=\"token punctuation\">(</span>isMatch<span class=\"token punctuation\">)</span> \n <span class=\"token punctuation\">&#125;</span>\n <span class=\"token keyword\">def</span> getMatchedRDD2<span class=\"token punctuation\">(</span>rdd<span class=\"token operator\">:</span> RDD<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n <span class=\"token keyword\">val</span> q <span class=\"token operator\">=</span> query\n rdd<span class=\"token punctuation\">.</span>filter<span class=\"token punctuation\">(</span>_<span class=\"token punctuation\">.</span>contains<span class=\"token punctuation\">(</span>q<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n <span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">&#125;</span>\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n\n\n<h4 id=\"5-1-4-7-RDD依赖关系\"><a href=\"#5-1-4-7-RDD依赖关系\" class=\"headerlink\" title=\"5.1.4.7 RDD依赖关系\"></a>5.1.4.7 RDD依赖关系</h4><p>1、RDD 血缘关系</p>\n<p>RDD 只支持粗粒度转换，即在大量记录上执行的单个操作。将创建 RDD 的一系列 Lineage （血统）记录下来，以便恢复丢失的分区。RDD 的 Lineage 会记录 <strong>RDD 的元数据信息和转换行为</strong>，当该 RDD 的部分分区数据丢失时，它可以根据这些信息来<strong>重新运算</strong>和恢复丢失的 数据分区。</p>\n<p>2、RDD 依赖关系</p>\n<p>两个相邻 RDD 之间的关系</p>\n<p>3、RDD 窄依赖</p>\n<p>窄依赖表示每一个父(上游)RDD 的 Partition 最多被子（下游）RDD 的一个 Partition 使用， 窄依赖我们形象的比喻为独生子女。</p>\n<p>4、RDD 宽依赖</p>\n<p>宽依赖表示同一个父（上游）RDD 的 Partition 被多个子（下游）RDD 的 Partition 依赖，会 引起 Shuffle，宽依赖我们形象的比喻为多生。</p>\n<p>5、RDD 阶段划分</p>\n<p>DAG（Directed Acyclic Graph）有向无环图是由点和线组成的拓扑图形，该图形具有方向， 不会闭环。例如，DAG 记录了 RDD 的转换过程和任务的阶段。</p>\n<p>6、RDD 阶段划分源码</p>\n<p>7、RDD 任务划分</p>\n<p>RDD 任务切分中间分为：Application、Job、Stage 和 Task</p>\n<p>​    ⚫ Application：初始化一个 SparkContext 即生成一个 Application；（setAppName）</p>\n<p>​    ⚫ Job：一个 Action 算子就会生成一个 Job； （底层runJob &#x3D;&gt; activeJob）</p>\n<p>​    ⚫ Stage：<strong>Stage 等于宽依赖(ShuffleDependency)的个数加 1</strong>； </p>\n<p>​    ⚫ Task：一个 Stage 阶段中，最后一个 RDD 的分区个数就是 Task 的个数。</p>\n<p><span style=\"color:red\">注意：Application-&gt;Job-&gt;Stage-&gt;Task 每一层都是 1 对 n 的关系</span></p>\n<p>8、RDD 任务划分源码</p>\n<h4 id=\"5-1-4-8-RDD持久化\"><a href=\"#5-1-4-8-RDD持久化\" class=\"headerlink\" title=\"5.1.4.8 RDD持久化\"></a>5.1.4.8 RDD持久化</h4><p>持久化就是把一些东西保存下来，之前不是rdd不存储数据，而是封装逻辑吗，但是有些我们需要高频使用的rdd，不能每次都去运行一遍得到，这种时候就用到了持久化</p>\n<p>1、RDD Cache 缓存</p>\n<p>cache默认只保存到内存中，cache和persist都是一样的，只是参数不同</p>\n<ul>\n<li><p><code>RDD.cache()</code> &#x3D; <code>RDD.persist(StorageLevel.MEMORY_ONLY)</code>：保存到内存</p>\n</li>\n<li><p><code>RDD.persist()</code>：保存到临时文件</p>\n</li>\n</ul>\n<hr />\n\n<p>2、RDD CheckPoint 检查点</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>所谓的检查点其实就是通过将 RDD 中间结果写入磁盘 </p></blockquote>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>由于血缘依赖过长会造成容错成本过高，这样就不如在中间阶段做检查点容错，</p></blockquote>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>如果检查点 之后有节点出现问题，可以从检查点开始重做血缘，减少了开销。</p></blockquote>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>对 RDD 进行 checkpoint 操作并不会马上被执行，必须执行 Action 操作才能触发。</p></blockquote>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token comment\">//在环境中设置checkpoint路径</span>\nsc<span class=\"token punctuation\">.</span>setCheckpointDir<span class=\"token punctuation\">(</span><span class=\"token string\">\"./checkpoint1\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">// 增加缓存,避免再重新跑一个 job 做 checkpoint</span>\nwordToOneRdd<span class=\"token punctuation\">.</span>cache<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\">// 数据检查点：针对 wordToOneRdd 做检查点计算</span>\nwordToOneRdd<span class=\"token punctuation\">.</span>checkpoint<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\">// 触发执行逻辑</span>\nwordToOneRdd<span class=\"token punctuation\">.</span>collect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>foreach<span class=\"token punctuation\">(</span>println<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<ul>\n<li>checkpoint 需要落盘，需要<strong>指定你检查点保持路径</strong></li>\n<li>检查点路径中保持的文件，当作业执行完毕后，不会被删除，刚刚的persist保持的是临时文件，运行完毕会被删除</li>\n<li>一般检查点<strong>保存在分布式路径</strong>中</li>\n</ul>\n<hr />\n\n<p>3、缓存和检查点区别</p>\n<ul>\n<li>cache：将数据存储到<strong>内存</strong>中进行数据重用</li>\n<li>persist：将数据临时存储在<strong>磁盘文件</strong>中进行数据重用，<ul>\n<li>​    设计磁盘io，<strong>性能低</strong>但是<strong>数据安全</strong>，</li>\n<li>​    如果作业执行完毕，<strong>临时保存的数据文件就会丢失</strong></li>\n</ul>\n</li>\n<li>checkpoint：将数据长久保存在磁盘文件中进行数据重用<ul>\n<li>数据安全 效率较低</li>\n<li>可以在不同的项目中引用</li>\n<li>为了保证数据安全，所以一般情况下，<strong>会独立再执行一次作业</strong>，所以效率更低了，刚刚的打印也能看到确实走了两遍</li>\n<li>为了提高效率一般情况下与cache联合使用</li>\n</ul>\n</li>\n</ul>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">rdd.cache()\nrdd.checkpoint() &#x2F;&#x2F;这个就只执行一次<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n\n\n\n<p>1）Cache 缓存只是将数据保存起来，不切断血缘依赖。Checkpoint 检查点切断血缘依赖。 </p>\n<p>2）Cache 缓存的数据通常存储在磁盘、内存等地方，可靠性低。Checkpoint 的数据通常存 储在 HDFS 等容错、高可用的文件系统，可靠性高。 </p>\n<p>3）建议对 checkpoint()的 RDD 使用 Cache 缓存，这样 checkpoint 的 job 只需从 Cache 缓存 中读取数据即可，否则需要再从头计算一次 RDD</p>\n<hr />\n\n<h2 id=\"5-2-累加器\"><a href=\"#5-2-累加器\" class=\"headerlink\" title=\"5.2 累加器\"></a>5.2 累加器</h2><p>累加器用来把 Executor 端变量信息<strong>聚合</strong>到 Driver 端。在 Driver 程序中定义的变量，在 Executor 端的每个 Task 都会得到这个变量的一份新的副本，每个 task 更新这些副本的值后， 传回 Driver 端进行 merge。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>分布式 共享 只写变量</p>\n<p>分布式：</p>\n<p>共享：被多个</p>\n<p>只写：多个executor的累加器是不能互相访问的，只有driver中可以访问其他executor的变量</p></blockquote>\n<p>使用：</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">val</span> sumAcc <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>longAccumulator<span class=\"token punctuation\">(</span><span class=\"token string\">\"sum\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">var</span> unit<span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> rdd<span class=\"token punctuation\">.</span>foreach<span class=\"token punctuation\">(</span>\n      num <span class=\"token keyword\">=></span> <span class=\"token punctuation\">&#123;</span>\n        sumAcc<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>num<span class=\"token punctuation\">)</span>\n      <span class=\"token punctuation\">&#125;</span>\n    <span class=\"token punctuation\">)</span>\nprintln<span class=\"token punctuation\">(</span>sumAcc<span class=\"token punctuation\">.</span>value<span class=\"token punctuation\">)</span>\n<span class=\"token comment\">/*\nsc.doubleAccumulator()\nsc.collectionAccumulator()\n*/</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">package com.atguigu.bigdata.spark.core.acc\n\nimport org.apache.spark.&#123;SparkConf, SparkContext&#125;\n\nobject Spark02_Acc &#123;\n  def main(args: Array[String]): Unit &#x3D; &#123;\n    val sparkConf &#x3D; new SparkConf().setMaster(&quot;local[*]&quot;).setAppName(&quot;Partition&quot;)\n    val sc &#x3D; new SparkContext(sparkConf)\n\n    val rdd &#x3D; sc.makeRDD(List(1, 2, 3, 4))\n\n    val sumAcc &#x3D; sc.longAccumulator(&quot;sum&quot;)\n\n    &#x2F;&#x2F;sc.collectionAccumulator() long double coullection\n\n    var unit: Unit &#x3D; rdd.foreach(\n      num &#x3D;&gt; &#123;\n        sumAcc.add(num)\n      &#125;\n    )\n\n\n\n\n    sc.stop()\n  &#125;\n&#125;\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>存在的问题：</p>\n<ul>\n<li>少加：光有想法不行动 转换算子调用累加器，如果<strong>没有行动算子</strong>的话，那么不会执行</li>\n<li>多加：行动多了，行动了两次</li>\n</ul>\n<p>解决方法：一般情况下累加器会<strong>放到行动算子中操作</strong> 也就是上文的foreach那种</p>\n<p>用处：<strong>简单数据的累加</strong> &#x3D;&gt; wordCount</p>\n<p>把要用shuffle的用累加器实现，比如wordcount</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>atguigu<span class=\"token punctuation\">.</span>bigdata<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>core<span class=\"token punctuation\">.</span>acc</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>util<span class=\"token punctuation\">.</span></span>AccumulatorV2\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">&#123;</span>SparkConf<span class=\"token punctuation\">,</span> SparkContext<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">scala<span class=\"token punctuation\">.</span>collection<span class=\"token punctuation\">.</span>mutable</span>\n\n<span class=\"token keyword\">object</span> Spark04_ACC_WordCount <span class=\"token punctuation\">&#123;</span>\n  <span class=\"token keyword\">def</span> main<span class=\"token punctuation\">(</span>args<span class=\"token operator\">:</span> Array<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token keyword\">val</span> sparkConf <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setMaster<span class=\"token punctuation\">(</span><span class=\"token string\">\"local[*]\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"Partition\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">val</span> sc <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkContext<span class=\"token punctuation\">(</span>sparkConf<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">val</span> rdd <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span>\n      <span class=\"token string\">\"hello\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"word\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"hello\"</span>\n    <span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//累加器：wordcount</span>\n    <span class=\"token comment\">//给的都不行，要自己来定义</span>\n    <span class=\"token comment\">//1. 创建累加器</span>\n\n    <span class=\"token keyword\">val</span> wcAcc <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> MyAccumulator<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">//2. 向spark注册</span>\n    sc<span class=\"token punctuation\">.</span>register<span class=\"token punctuation\">(</span>wcAcc<span class=\"token punctuation\">,</span><span class=\"token string\">\"wordCountACC\"</span><span class=\"token punctuation\">)</span>\n\n\n\n    <span class=\"token keyword\">val</span> wc <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>longAccumulator<span class=\"token punctuation\">(</span><span class=\"token string\">\"WordC\"</span><span class=\"token punctuation\">)</span>\n\n    rdd<span class=\"token punctuation\">.</span>foreach<span class=\"token punctuation\">(</span>\n      word <span class=\"token keyword\">=></span> <span class=\"token punctuation\">&#123;</span>\n        <span class=\"token comment\">//使用累加器</span>\n        wcAcc<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">)</span>\n      <span class=\"token punctuation\">&#125;</span>\n    <span class=\"token punctuation\">)</span>\n\n\n    <span class=\"token comment\">//获取结果</span>\n    println<span class=\"token punctuation\">(</span>wcAcc<span class=\"token punctuation\">.</span>value<span class=\"token punctuation\">)</span>\n\n\n\n  <span class=\"token punctuation\">&#125;</span>\n  <span class=\"token comment\">/*\n  自定义数据累加器\n\n\n\n\n\n  //1. 继承AccumulatorV2，定义泛型\n    IN: 输入的数据类型 => String\n    OUT:返回的数据类型 => map\n\n\n   */</span>\n  <span class=\"token keyword\">class</span> MyAccumulator<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">extends</span> AccumulatorV2<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">,</span> mutable<span class=\"token punctuation\">.</span>Map<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">Long</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token keyword\">private</span> <span class=\"token keyword\">var</span> wcMap <span class=\"token operator\">=</span> mutable<span class=\"token punctuation\">.</span>Map<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">Long</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n\n    <span class=\"token comment\">//2. 实现方法</span>\n\n\n    <span class=\"token comment\">//这个属性名表示初始的意思 该方法用于判断是否是初始状态</span>\n    <span class=\"token keyword\">override</span> <span class=\"token keyword\">def</span> isZero<span class=\"token operator\">:</span> <span class=\"token builtin\">Boolean</span> <span class=\"token operator\">=</span> wcMap<span class=\"token punctuation\">.</span>isEmpty\n\n\n    <span class=\"token comment\">//复制一个新的累加器</span>\n    <span class=\"token keyword\">override</span> <span class=\"token keyword\">def</span> copy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> AccumulatorV2<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">,</span> mutable<span class=\"token punctuation\">.</span>Map<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">Long</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> MyAccumulator<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">override</span> <span class=\"token keyword\">def</span> reset<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> wcMap<span class=\"token punctuation\">.</span>clear<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n\n    <span class=\"token comment\">// 获取累加器需要计算的值</span>\n    <span class=\"token keyword\">override</span> <span class=\"token keyword\">def</span> add<span class=\"token punctuation\">(</span>v<span class=\"token operator\">:</span> <span class=\"token builtin\">String</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n      <span class=\"token keyword\">var</span> newCnt <span class=\"token operator\">=</span> wcMap<span class=\"token punctuation\">.</span>getOrElse<span class=\"token punctuation\">(</span>v<span class=\"token punctuation\">,</span> <span class=\"token number\">0L</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> <span class=\"token number\">1</span>\n      wcMap<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span>v<span class=\"token punctuation\">,</span> newCnt<span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">&#125;</span>\n\n    <span class=\"token comment\">// Driver端的合并</span>\n    <span class=\"token keyword\">override</span> <span class=\"token keyword\">def</span> merge<span class=\"token punctuation\">(</span>other<span class=\"token operator\">:</span> AccumulatorV2<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">,</span> mutable<span class=\"token punctuation\">.</span>Map<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">Long</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n      <span class=\"token keyword\">val</span> map1 <span class=\"token operator\">=</span> <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>wcMap\n      <span class=\"token keyword\">val</span> map2 <span class=\"token operator\">=</span> other<span class=\"token punctuation\">.</span>value\n\n      map2<span class=\"token punctuation\">.</span>foreach<span class=\"token punctuation\">&#123;</span>\n        <span class=\"token keyword\">case</span> <span class=\"token punctuation\">(</span>v<span class=\"token punctuation\">,</span> count<span class=\"token punctuation\">)</span> <span class=\"token keyword\">=></span> <span class=\"token punctuation\">&#123;</span>\n        <span class=\"token keyword\">val</span> newCount <span class=\"token operator\">=</span> map1<span class=\"token punctuation\">.</span>getOrElse<span class=\"token punctuation\">(</span>v<span class=\"token punctuation\">,</span> <span class=\"token number\">0L</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> count\n        map1<span class=\"token punctuation\">.</span>update<span class=\"token punctuation\">(</span>v<span class=\"token punctuation\">,</span> newCount<span class=\"token punctuation\">)</span>\n      <span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#125;</span>\n\n\n    <span class=\"token punctuation\">&#125;</span>\n\n\n    <span class=\"token comment\">//累加器结果</span>\n    <span class=\"token keyword\">override</span> <span class=\"token keyword\">def</span> value<span class=\"token operator\">:</span> mutable<span class=\"token punctuation\">.</span>Map<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">,</span> <span class=\"token builtin\">Long</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> wcMap\n  <span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n<h2 id=\"5-3-广播变量\"><a href=\"#5-3-广播变量\" class=\"headerlink\" title=\"5.3 广播变量\"></a>5.3 广播变量</h2><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>分布式 共享 只读变量</p></blockquote>\n<p>广播变量用来<strong>高效分发较大的对象</strong>。向所有工作节点发送<strong>一个较大的只读值</strong>，以供一个 或多个 Spark 操作使用。比如，如果你的应用需要向所有节点发送一个较大的只读查询表， 广播变量用起来都很顺手。在多个<strong>并行</strong>操作中使用同一个变量，但是 Spark 会为每个任务 分别发送。</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token comment\">//将变量变为广播变量</span>\n<span class=\"token keyword\">val</span> bc <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>broadcast<span class=\"token punctuation\">(</span>map<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">//使用</span>\nbc<span class=\"token punctuation\">.</span>value\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>完整代码：</p>\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token keyword\">package</span> <span class=\"token namespace\">com<span class=\"token punctuation\">.</span>atguigu<span class=\"token punctuation\">.</span>bigdata<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span>core<span class=\"token punctuation\">.</span>acc</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">org<span class=\"token punctuation\">.</span>apache<span class=\"token punctuation\">.</span>spark<span class=\"token punctuation\">.</span></span><span class=\"token punctuation\">&#123;</span>SparkConf<span class=\"token punctuation\">,</span> SparkContext<span class=\"token punctuation\">&#125;</span>\n\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">scala<span class=\"token punctuation\">.</span></span>None<span class=\"token punctuation\">.</span>getOrElse\n<span class=\"token keyword\">import</span> <span class=\"token namespace\">scala<span class=\"token punctuation\">.</span>collection<span class=\"token punctuation\">.</span>mutable</span>\n\n<span class=\"token keyword\">object</span> Spark05_Bc <span class=\"token punctuation\">&#123;</span>\n  <span class=\"token keyword\">def</span> main<span class=\"token punctuation\">(</span>args<span class=\"token operator\">:</span> Array<span class=\"token punctuation\">[</span><span class=\"token builtin\">String</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token operator\">:</span> <span class=\"token builtin\">Unit</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token keyword\">val</span> sparkConf <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkConf<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setMaster<span class=\"token punctuation\">(</span><span class=\"token string\">\"local[*]\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>setAppName<span class=\"token punctuation\">(</span><span class=\"token string\">\"Partition\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">val</span> sc <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> SparkContext<span class=\"token punctuation\">(</span>sparkConf<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">val</span> rdd1 <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span>\n      <span class=\"token punctuation\">(</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n      <span class=\"token punctuation\">(</span><span class=\"token string\">\"b\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n      <span class=\"token punctuation\">(</span><span class=\"token string\">\"c\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">)</span>\n    <span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">val</span> map <span class=\"token operator\">=</span> mutable<span class=\"token punctuation\">.</span>Map<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"a\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"b\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"c\"</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">val</span> bc <span class=\"token operator\">=</span> sc<span class=\"token punctuation\">.</span>broadcast<span class=\"token punctuation\">(</span>map<span class=\"token punctuation\">)</span>\n\n    rdd1<span class=\"token punctuation\">.</span>map<span class=\"token punctuation\">&#123;</span>\n      <span class=\"token keyword\">case</span> <span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">,</span> c<span class=\"token punctuation\">)</span> <span class=\"token keyword\">=></span> <span class=\"token punctuation\">&#123;</span>\n        <span class=\"token comment\">//访问广播变量</span>\n        <span class=\"token keyword\">val</span> i <span class=\"token operator\">=</span> bc<span class=\"token punctuation\">.</span>value<span class=\"token punctuation\">.</span>getOrElse<span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">(</span>w<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>c <span class=\"token punctuation\">,</span>i<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n      <span class=\"token punctuation\">&#125;</span>\n    <span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">.</span>collect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>foreach<span class=\"token punctuation\">(</span>println<span class=\"token punctuation\">)</span>\n\n\n\n\n    sc<span class=\"token punctuation\">.</span>stop<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n  <span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n\n\n\n\n\n<h1 id=\"一些报错及解决-及-scala的方法\"><a href=\"#一些报错及解决-及-scala的方法\" class=\"headerlink\" title=\"一些报错及解决 及 scala的方法\"></a>一些报错及解决 及 scala的方法</h1><p>1、报错奇奇怪怪的：����: �Ҳ������޷���������<br>在maven的runner中</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20210323104253642.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmd5dWUwMzM=,size_16,color_FFFFFF,t_70#pic_center\"></p>\n<p>2、getOrElse</p>\n<p>如果值为非空则获取值，如果值为空则返回默认值</p>\n","feature":true,"text":"第3章 spark运行环境3.1 local模式3.2 standalone模式3.3 yarn模式（公司常用）3.4 k8s &amp; Mesos模式3.5 windows模式3.5.2 本地环境第4章 spark运行架构Driver 驱动器节点，执行spark任务中的mai...","link":"","photos":[],"count_time":{"symbolsCount":"20k","symbolsTime":"18 mins."},"categories":[],"tags":[{"name":"spark","slug":"spark","count":1,"path":"api/tags/spark.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E7%AC%AC3%E7%AB%A0-spark%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83\"><span class=\"toc-text\">第3章 spark运行环境</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#3-1-local%E6%A8%A1%E5%BC%8F\"><span class=\"toc-text\">3.1 local模式</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-2-standalone%E6%A8%A1%E5%BC%8F\"><span class=\"toc-text\">3.2 standalone模式</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-3-yarn%E6%A8%A1%E5%BC%8F%EF%BC%88%E5%85%AC%E5%8F%B8%E5%B8%B8%E7%94%A8%EF%BC%89\"><span class=\"toc-text\">3.3 yarn模式（公司常用）</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-4-k8s-amp-Mesos%E6%A8%A1%E5%BC%8F\"><span class=\"toc-text\">3.4 k8s &amp; Mesos模式</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3-5-windows%E6%A8%A1%E5%BC%8F\"><span class=\"toc-text\">3.5 windows模式</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#3-5-2-%E6%9C%AC%E5%9C%B0%E7%8E%AF%E5%A2%83\"><span class=\"toc-text\">3.5.2 本地环境</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E7%AC%AC4%E7%AB%A0-spark%E8%BF%90%E8%A1%8C%E6%9E%B6%E6%9E%84\"><span class=\"toc-text\">第4章 spark运行架构</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E7%AC%AC5%E7%AB%A0-spark%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B\"><span class=\"toc-text\">第5章 spark核心编程</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#5-1-RDD\"><span class=\"toc-text\">5.1 RDD</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#5-1-1-%E4%BB%80%E4%B9%88%E6%98%AFRDD\"><span class=\"toc-text\">5.1.1 什么是RDD</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#5-1-2-%E6%A0%B8%E5%BF%83%E5%B1%9E%E6%80%A7\"><span class=\"toc-text\">5.1.2 核心属性</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#5-1-3-%E6%89%A7%E8%A1%8C%E5%8E%9F%E7%90%86\"><span class=\"toc-text\">5.1.3 执行原理</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#5-1-4-%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B\"><span class=\"toc-text\">5.1.4 基础编程</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#5-1-4-1-RDD%E5%88%9B%E5%BB%BA\"><span class=\"toc-text\">5.1.4.1 RDD创建</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#5-1-4-2-RDD%E5%B9%B6%E8%A1%8C%E5%BA%A6%E4%B8%8E%E5%88%86%E5%8C%BA\"><span class=\"toc-text\">5.1.4.2 RDD并行度与分区</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#5-1-4-3-RDD%E8%BD%AC%E6%8D%A2%E7%AE%97%E5%AD%90-%E9%87%8D%E7%82%B9\"><span class=\"toc-text\">5.1.4.3 RDD转换算子(重点)</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#1-value%E7%B1%BB%E5%9E%8B\"><span class=\"toc-text\">1. value类型</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#01%E3%80%81map\"><span class=\"toc-text\">01、map</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#02%E3%80%81mapPartitions\"><span class=\"toc-text\">02、mapPartitions</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#03%E3%80%81mapPartitionsWithIndex\"><span class=\"toc-text\">03、mapPartitionsWithIndex</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#04%E3%80%81flatMap\"><span class=\"toc-text\">04、flatMap</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#05%E3%80%81glom\"><span class=\"toc-text\">05、glom</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#06%E3%80%81groupBy\"><span class=\"toc-text\">06、groupBy</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#07%E3%80%81filter\"><span class=\"toc-text\">07、filter</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#08%E3%80%81sample\"><span class=\"toc-text\">08、sample</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#09%E3%80%81distinct\"><span class=\"toc-text\">09、distinct</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#10%E3%80%81coalesce\"><span class=\"toc-text\">10、coalesce</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#11%E3%80%81repartition\"><span class=\"toc-text\">11、repartition</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#12%E3%80%81sortBy\"><span class=\"toc-text\">12、sortBy</span></a></li></ol></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#2-%E5%8F%8Cvalue%E7%B1%BB%E5%9E%8B\"><span class=\"toc-text\">2. 双value类型</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#01%E3%80%81intersection\"><span class=\"toc-text\">01、intersection</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#02%E3%80%81union\"><span class=\"toc-text\">02、union</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#03%E3%80%81subtract\"><span class=\"toc-text\">03、subtract</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#04%E3%80%81zip\"><span class=\"toc-text\">04、zip</span></a></li></ol></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#3-key-value%E7%B1%BB%E5%9E%8B\"><span class=\"toc-text\">3. key-value类型</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#01%E3%80%81partitionBy\"><span class=\"toc-text\">01、partitionBy</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#02%E3%80%81reduceByKey\"><span class=\"toc-text\">02、reduceByKey</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#03%E3%80%81groupByKey\"><span class=\"toc-text\">03、groupByKey</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#04%E3%80%81aggregateByKey\"><span class=\"toc-text\">04、aggregateByKey</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#05%E3%80%81foldByKey\"><span class=\"toc-text\">05、foldByKey</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#06%E3%80%81combineByKey\"><span class=\"toc-text\">06、combineByKey</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#07%E3%80%81sortByKey\"><span class=\"toc-text\">07、sortByKey</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#08%E3%80%81join\"><span class=\"toc-text\">08、join</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#09%E3%80%81leftOuterJoin\"><span class=\"toc-text\">09、leftOuterJoin</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#10%E3%80%81cogroup\"><span class=\"toc-text\">10、cogroup</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#11%E3%80%81mapValues\"><span class=\"toc-text\">11、mapValues</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#5-1-4-4-%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D\"><span class=\"toc-text\">5.1.4.4 案例实操</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#5-1-4-5-%E8%A1%8C%E5%8A%A8%E7%AE%97%E5%AD%90\"><span class=\"toc-text\">5.1.4.5 行动算子</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#1%E3%80%81reduce\"><span class=\"toc-text\">1、reduce</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#2%E3%80%81collect\"><span class=\"toc-text\">2、collect</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#3%E3%80%81count\"><span class=\"toc-text\">3、count</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#4%E3%80%81first\"><span class=\"toc-text\">4、first</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#5%E3%80%81take\"><span class=\"toc-text\">5、take</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#6%E3%80%81takeOrderd\"><span class=\"toc-text\">6、takeOrderd</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#7%E3%80%81aggregate\"><span class=\"toc-text\">7、aggregate</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#8%E3%80%81fold\"><span class=\"toc-text\">8、fold</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#9%E3%80%81countByKey\"><span class=\"toc-text\">9、countByKey</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#10%E3%80%81save%E7%9B%B8%E5%85%B3%E7%AE%97%E5%AD%90\"><span class=\"toc-text\">10、save相关算子</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#11%E3%80%81foreach\"><span class=\"toc-text\">11、foreach</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#5-1-4-6-RDD%E5%BA%8F%E5%88%97%E5%8C%96\"><span class=\"toc-text\">5.1.4.6 RDD序列化</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#5-1-4-7-RDD%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB\"><span class=\"toc-text\">5.1.4.7 RDD依赖关系</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#5-1-4-8-RDD%E6%8C%81%E4%B9%85%E5%8C%96\"><span class=\"toc-text\">5.1.4.8 RDD持久化</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#5-2-%E7%B4%AF%E5%8A%A0%E5%99%A8\"><span class=\"toc-text\">5.2 累加器</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#5-3-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F\"><span class=\"toc-text\">5.3 广播变量</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%B8%80%E4%BA%9B%E6%8A%A5%E9%94%99%E5%8F%8A%E8%A7%A3%E5%86%B3-%E5%8F%8A-scala%E7%9A%84%E6%96%B9%E6%B3%95\"><span class=\"toc-text\">一些报错及解决 及 scala的方法</span></a></li></ol>","author":{"name":"Cencus","slug":"blog-author","avatar":"https://gitee.com/cencus/blog-image/raw/master/blogImage/1648381409561.jpg","link":"/","description":"stay hungry, stay foolish.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{},"next_post":{"title":"scala","uid":"a5d8f8aa75a85d4533d622d4e92bd3f1","slug":"scala","date":"2022-04-05T07:52:16.000Z","updated":"2022-04-09T11:04:15.302Z","comments":true,"path":"api/articles/scala.json","keywords":null,"cover":null,"text":"第1章 入门基于JVM，与Java关系密切 Java是一门先编译后解释的语言 Scala与java一样 特点：融合怪 面向对象 函数式编程 静态类型（类型提前声明指定）编程语言 多范式 结合了面对对象与函数式编程 .scala会被编译为java字节码.class，然后运行在JVM...","link":"","photos":[],"count_time":{"symbolsCount":"7.5k","symbolsTime":"7 mins."},"categories":[],"tags":[{"name":"语言，Scala，大数据","slug":"语言，Scala，大数据","count":1,"path":"api/tags/语言，Scala，大数据.json"}],"author":{"name":"Cencus","slug":"blog-author","avatar":"https://gitee.com/cencus/blog-image/raw/master/blogImage/1648381409561.jpg","link":"/","description":"stay hungry, stay foolish.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true}}