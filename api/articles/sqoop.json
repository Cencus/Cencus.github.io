{"title":"sqoop","uid":"2fc87cccb261708e4dc237f0341aa59b","slug":"sqoop","date":"2022-04-14T10:50:02.000Z","updated":"2022-04-14T11:01:14.779Z","comments":true,"path":"api/articles/sqoop.json","keywords":null,"cover":null,"content":"<p>sql to hadoop</p>\n<p>使用1</p>\n<p>翻译成MapReduce对inputformat和outputformat进行定制</p>\n<p>安装</p>\n<p>下载：<a href=\"http://archive.apache.org/dist/sqoop/1.4.6/\">http://archive.apache.org/dist/sqoop/1.4.6/</a></p>\n<p>tar -zxvf -C &#x2F;opt&#x2F;module</p>\n<p>#Set path to where bin&#x2F;hadoop is available<br>export HADOOP_COMMON_HOME&#x3D;&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3</p>\n<p>#Set path to where hadoop-*-core.jar is available<br>export HADOOP_MAPRED_HOME&#x3D;&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3</p>\n<p>#set the path to where bin&#x2F;hbase is available<br>#export HBASE_HOME&#x3D;</p>\n<p>#Set the path to where bin&#x2F;hive is available<br>export HIVE_HOME&#x3D;&#x2F;opt&#x2F;module&#x2F;hive</p>\n<p>#Set the path for where zookeper config dir is</p>\n<p>export ZOOCFGDIR&#x3D;&#x2F;opt&#x2F;module&#x2F;zookeeper-3.6.3</p>\n<p>bin&#x2F;sqoop help</p>\n<p>bin&#x2F;sqoop list-databases –connect jdbc:mysql:&#x2F;&#x2F;hadoop102:3306&#x2F; –username root –password 111111</p>\n","text":"sql to hadoop 使用1 翻译成MapReduce对inputformat和outputformat进行定制 安装 下载：http://archive.apache.org/dist/sqoop/1.4.6/ tar -zxvf -C &#x2F;opt&#x2F;mo...","link":"","photos":[],"count_time":{"symbolsCount":808,"symbolsTime":"1 mins."},"categories":[],"tags":[],"toc":"","author":{"name":"Cencus","slug":"blog-author","avatar":"https://gitee.com/cencus/blog-image/raw/master/blogImage/1648381409561.jpg","link":"/","description":"stay hungry, stay foolish.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"spark-sql","uid":"c4e1f631332880dad580bd689797a6a3","slug":"spark-sql","date":"2022-04-16T12:49:55.000Z","updated":"2022-04-18T03:02:09.738Z","comments":true,"path":"api/articles/spark-sql.json","keywords":null,"cover":[],"text":"第1章 SparkSQL 概述1.3 SparkSQL 特点1.3.1 易整合无缝的整合了 SQL 查询和 Spark 编程 1.3.2 统一的数据访问使用相同的方式连接不同的数据源 1.3.3 兼容Hive 在已有的仓库上直接运行 SQL 或者 HiveQL 1.3.4 标准数...","link":"","photos":[],"count_time":{"symbolsCount":"16k","symbolsTime":"15 mins."},"categories":[],"tags":[{"name":"spark","slug":"spark","count":2,"path":"api/tags/spark.json"}],"author":{"name":"Cencus","slug":"blog-author","avatar":"https://gitee.com/cencus/blog-image/raw/master/blogImage/1648381409561.jpg","link":"/","description":"stay hungry, stay foolish.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"spark","uid":"e04902dcdb07e2ad1898c41f1efa8f40","slug":"spark","date":"2022-04-08T12:55:34.000Z","updated":"2022-04-17T02:45:10.830Z","comments":true,"path":"api/articles/spark.json","keywords":null,"cover":[],"text":"第3章 spark运行环境3.1 local模式3.2 standalone模式3.3 yarn模式（公司常用）3.4 k8s &amp; Mesos模式3.5 windows模式3.5.2 本地环境3.7 端口号➢ Spark 查看当前 Spark-shell 运行任务情况端口...","link":"","photos":[],"count_time":{"symbolsCount":"20k","symbolsTime":"18 mins."},"categories":[],"tags":[{"name":"spark","slug":"spark","count":2,"path":"api/tags/spark.json"}],"author":{"name":"Cencus","slug":"blog-author","avatar":"https://gitee.com/cencus/blog-image/raw/master/blogImage/1648381409561.jpg","link":"/","description":"stay hungry, stay foolish.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}