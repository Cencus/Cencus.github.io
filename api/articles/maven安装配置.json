{"title":"maven安装配置","uid":"29fb3d0ec9f011ab95928547f0ea4133","slug":"maven安装配置","date":"2022-04-17T02:59:20.000Z","updated":"2022-04-17T03:23:00.337Z","comments":true,"path":"api/articles/maven安装配置.json","keywords":null,"cover":null,"content":"<pre class=\"line-numbers language-xml\" data-language=\"xml\"><code class=\"language-xml\"><span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>mirror</span><span class=\"token punctuation\">></span></span>  \n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>id</span><span class=\"token punctuation\">></span></span>nexus-aliyun<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>id</span><span class=\"token punctuation\">></span></span>  \n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>mirrorOf</span><span class=\"token punctuation\">></span></span>central<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>mirrorOf</span><span class=\"token punctuation\">></span></span>    \n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>name</span><span class=\"token punctuation\">></span></span>Nexus aliyun<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>name</span><span class=\"token punctuation\">></span></span>  \n    <span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;</span>url</span><span class=\"token punctuation\">></span></span>http://maven.aliyun.com/nexus/content/groups/public<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>url</span><span class=\"token punctuation\">></span></span>  \n<span class=\"token tag\"><span class=\"token tag\"><span class=\"token punctuation\">&lt;/</span>mirror</span><span class=\"token punctuation\">></span></span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n\n\n<pre class=\"line-numbers language-scala\" data-language=\"scala\"><code class=\"language-scala\"><span class=\"token comment\">//DataSet</span>\n<span class=\"token comment\">//DataFrame其实是特定泛型的DataSet DataFrame = DataSet[Row]</span>\n<span class=\"token keyword\">val</span> seq <span class=\"token operator\">=</span> Seq<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span><span class=\"token number\">4</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">val</span> ds<span class=\"token operator\">:</span> DataSet<span class=\"token punctuation\">[</span><span class=\"token builtin\">Int</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> seq<span class=\"token punctuation\">.</span>toDS<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nds<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\">//使用dataframe的东西</span>\nds<span class=\"token punctuation\">.</span>select<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n\n\n<span class=\"token comment\">//RDD &lt;=> DataFrame</span>\n<span class=\"token keyword\">val</span> rdd <span class=\"token operator\">=</span> spark<span class=\"token punctuation\">.</span>sparkContext<span class=\"token punctuation\">.</span>makeRDD<span class=\"token punctuation\">(</span>List<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"zhangsan\"</span><span class=\"token punctuation\">,</span><span class=\"token number\">30</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span><span class=\"token string\">\"lisi\"</span><span class=\"token punctuation\">,</span><span class=\"token number\">40</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">val</span> df<span class=\"token operator\">:</span> DataFrame <span class=\"token operator\">=</span> rowRDD<span class=\"token punctuation\">.</span>toDF<span class=\"token punctuation\">(</span><span class=\"token string\">\"id\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"name\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"age\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\">//df to rdd</span>\n<span class=\"token keyword\">val</span> rowRDD<span class=\"token operator\">:</span> RDD<span class=\"token punctuation\">[</span>Row<span class=\"token punctuation\">]</span><span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span>rdd\n\n\n<span class=\"token comment\">//DataFrame &lt;=> DataSet</span>\n<span class=\"token keyword\">val</span> ds<span class=\"token operator\">:</span>DataSet<span class=\"token punctuation\">[</span>User<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> df<span class=\"token punctuation\">.</span>as<span class=\"token punctuation\">[</span>User<span class=\"token punctuation\">]</span>\n<span class=\"token keyword\">val</span> df1<span class=\"token operator\">:</span>DataFrame <span class=\"token operator\">=</span> ds<span class=\"token punctuation\">.</span>toDF<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n\n<span class=\"token comment\">//RDD &lt;=> DataSet</span>\n\n\n\n\n\n\n\n\n\n\n<span class=\"token keyword\">case</span> <span class=\"token keyword\">class</span> User<span class=\"token punctuation\">(</span>id<span class=\"token operator\">:</span> <span class=\"token builtin\">Int</span><span class=\"token punctuation\">,</span> name<span class=\"token operator\">:</span> <span class=\"token builtin\">String</span><span class=\"token punctuation\">,</span> age<span class=\"token operator\">:</span> <span class=\"token builtin\">Int</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n","feature":true,"text":"&lt;mirror> &lt;id>nexus-aliyun&lt;/id> &lt;mirrorOf>central&lt;/mirrorOf> &lt;name>Nexus aliyun&lt;/name> &lt;url>http://maven.aliyun.com/n...","link":"","photos":[],"count_time":{"symbolsCount":753,"symbolsTime":"1 mins."},"categories":[],"tags":[],"toc":"","author":{"name":"Cencus","slug":"blog-author","avatar":"https://gitee.com/cencus/blog-image/raw/master/blogImage/1648381409561.jpg","link":"/","description":"stay hungry, stay foolish.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"flink","uid":"5e9344771dc8b58a27dc2310ded3b07a","slug":"flink","date":"2022-04-19T02:46:59.000Z","updated":"2022-04-19T07:50:07.166Z","comments":true,"path":"api/articles/flink.json","keywords":null,"cover":[],"text":"入门flink是什么Apache Flink 是一个框架和分布式处理引擎，用于对无界和有界数据流进行状态计算。 why flink➢ 低延迟 ➢ 高吞吐 ➢ 结果的准确性和良好的容错性 什么叫做状态计算 不与数据库交互，而是直接与内存里的数据交互，保存了通过数据的状态，比如wor...","link":"","photos":[],"count_time":{"symbolsCount":540,"symbolsTime":"1 mins."},"categories":[],"tags":[{"name":"流处理，实时数据处理","slug":"流处理，实时数据处理","count":1,"path":"api/tags/流处理，实时数据处理.json"},{"name":"flink","slug":"flink","count":1,"path":"api/tags/flink.json"}],"author":{"name":"Cencus","slug":"blog-author","avatar":"https://gitee.com/cencus/blog-image/raw/master/blogImage/1648381409561.jpg","link":"/","description":"stay hungry, stay foolish.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"spark-sql","uid":"c4e1f631332880dad580bd689797a6a3","slug":"spark-sql","date":"2022-04-16T12:49:55.000Z","updated":"2022-04-18T03:02:09.738Z","comments":true,"path":"api/articles/spark-sql.json","keywords":null,"cover":[],"text":"第1章 SparkSQL 概述1.3 SparkSQL 特点1.3.1 易整合无缝的整合了 SQL 查询和 Spark 编程 1.3.2 统一的数据访问使用相同的方式连接不同的数据源 1.3.3 兼容Hive 在已有的仓库上直接运行 SQL 或者 HiveQL 1.3.4 标准数...","link":"","photos":[],"count_time":{"symbolsCount":"16k","symbolsTime":"15 mins."},"categories":[],"tags":[{"name":"spark","slug":"spark","count":2,"path":"api/tags/spark.json"}],"author":{"name":"Cencus","slug":"blog-author","avatar":"https://gitee.com/cencus/blog-image/raw/master/blogImage/1648381409561.jpg","link":"/","description":"stay hungry, stay foolish.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true}}