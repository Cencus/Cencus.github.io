{"title":"面试","uid":"b8cee04dc0368bcbafd67939edc1c0b9","slug":"面试","date":"2022-05-01T02:58:09.000Z","updated":"2022-05-02T03:46:20.236Z","comments":true,"path":"api/articles/面试.json","keywords":null,"cover":[],"content":"<h1 id=\"一、Linux-amp-Shell总结\"><a href=\"#一、Linux-amp-Shell总结\" class=\"headerlink\" title=\"一、Linux &amp; Shell总结\"></a>一、Linux &amp; Shell总结</h1><p>ps -ef</p>\n<p>只执行ps命令，默认是显示当前控制台下属于当前用户的进程；</p>\n<p>参数 -e 显示运行在系统上的所有进程</p>\n<p>参数 -f 扩展显示输出</p>\n<p>UID      启动进程的用户</p>\n<p>PID      进程的进程号</p>\n<p>PPID    父进程进程号</p>\n<p>C          cpu使用率</p>\n<p>STIME   进程启动时的系统时间</p>\n<p>TTY       进程启动时终端设备</p>\n<p>TIME     运行进程需要的累积CPU时间</p>\n<p>CMD   启动程序名称或命令</p>\n<p>df -h</p>\n<p>top</p>\n<p>iotop</p>\n<p>rpm -ivh</p>\n<p>netstat</p>\n<p>写过哪些脚本</p>\n<p>1、启动停止脚本、分发</p>\n<pre class=\"line-numbers language-shell\" data-language=\"shell\"><code class=\"language-shell\">#!bin&#x2F;bash\n\ncase $1 in\n&quot;start&quot;)&#123;\n    for i in hadoop102 hadoop103 hadoop104\n    do\n        ssh $i &quot;启动命令的绝对路径&quot;\n    done\n&#125;;;\n&quot;stop&quot;)&#123;\n    for i in hadoop102 hadoop103 hadoop104\n    do\n        ssh $i &quot;启动命令的绝对路径&quot;\n    done\n&#125;;;\nesac<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n\n\n<p>2、数仓层级内部导入</p>\n<p>ods &#x3D;&gt; dwd &#x3D;&gt; dws &#x3D;&gt; dwt &#x3D;&gt; ads</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">#!bin&#x2F;bash\n\n# 1. 定义变量 APP\n\n# 2. 获取时间\n\n# 3.\n# sql &#x3D; &quot;\n#     具体的sql；（先写一天的，然后在表名前面加上$APP,将时间换成$do_date）\n# &quot;\n\n# 4. 执行sql<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n\n\n\n\n<p>3、数仓与mysql的导入导出</p>\n<p>mysql sqoop hdfs</p>\n<p>shell 常用工具</p>\n<p>awk <a href=\"https://www.cnblogs.com/wwwdcsxudcom/p/15888073.html\">https://www.cnblogs.com/wwwdcsxudcom/p/15888073.html</a></p>\n<p>sed</p>\n<p>sort</p>\n<p>cut</p>\n<p>shell中单引号和双引号的区别</p>\n<p>单引号：’’在引号内部的变量不能解析里面变量对应的值，例如’$do_date’直接打印$do_date</p>\n<p>双引号：”$do_date”在双引号内部能够取出变量的值</p>\n<p>嵌套：看谁在最外层，”  ‘$do_date’  “可以取出。’ “$do_date” ‘不可以取出</p>\n<h1 id=\"Hadoop\"><a href=\"#Hadoop\" class=\"headerlink\" title=\"Hadoop\"></a>Hadoop</h1><h2 id=\"入门\"><a href=\"#入门\" class=\"headerlink\" title=\"入门\"></a>入门</h2><p>常用端口号</p>\n<table>\n<thead>\n<tr>\n<th>2.x端口</th>\n<th>3.x端口</th>\n<th>作用</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>50070</td>\n<td>9870</td>\n<td>HDFSWeb页面</td>\n</tr>\n<tr>\n<td></td>\n<td>19888</td>\n<td>历史服务器</td>\n</tr>\n<tr>\n<td></td>\n<td>8020&#x2F;9000</td>\n<td>客户端访问端口</td>\n</tr>\n<tr>\n<td></td>\n<td>8088</td>\n<td>MapReduce执行作业</td>\n</tr>\n</tbody></table>\n<p>安装配置文件</p>\n<p>2.x</p>\n<p>core-site.xml</p>\n<p>hdfs-site.xml</p>\n<p>mapred-site.xml</p>\n<p>yarn-site.xml</p>\n<p>slaves</p>\n<p>3.x</p>\n<p>core-site.xml</p>\n<p>hdfs-site.xml</p>\n<p>mapred-site.xml</p>\n<p>yarn-site.xml</p>\n<p>workers</p>\n<h2 id=\"HDFS\"><a href=\"#HDFS\" class=\"headerlink\" title=\"HDFS\"></a>HDFS</h2><p>1. </p>\n<p>2. </p>\n<ol start=\"3\">\n<li>HDFS默认有几个副本</li>\n</ol>\n<p>​            3个</p>\n<ol start=\"4\">\n<li>HDFS块大小</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th>方面</th>\n<th>大小</th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>2.x 3.x</td>\n<td>默认块 128m</td>\n<td></td>\n</tr>\n<tr>\n<td>2.x本地模式</td>\n<td>32m（看过源码）</td>\n<td></td>\n</tr>\n<tr>\n<td>1.x 块大小</td>\n<td>64m</td>\n<td></td>\n</tr>\n<tr>\n<td>hive的块大小</td>\n<td>256m</td>\n<td></td>\n</tr>\n<tr>\n<td>大仓企业块大小</td>\n<td>256m</td>\n<td></td>\n</tr>\n</tbody></table>\n<p>块大小取决于，服务器之间传输通信速度（速度越快，块大小越大）</p>\n<h2 id=\"MapReduce\"><a href=\"#MapReduce\" class=\"headerlink\" title=\"MapReduce\"></a>MapReduce</h2><p>shuffle及其优化</p>\n<p>shuffle是map方法之后，reduce方法之前，混洗的过程</p>\n<p>压缩</p>\n<p><img src=\"https://gitee.com/cencus/blog-image/raw/master/blogImage/1651377730092.png\"></p>\n<p>各项内存</p>\n<p><img src=\"https://gitee.com/cencus/blog-image/raw/master/blogImage/1651378355089.png\"></p>\n<h2 id=\"YARN\"><a href=\"#YARN\" class=\"headerlink\" title=\"YARN\"></a>YARN</h2><p>1、FIFO、容量调度器、公平调度器</p>\n<p>2、默认：</p>\n<ul>\n<li><p>Apache：默认容量</p>\n</li>\n<li><p>CDH：默认公平</p>\n</li>\n</ul>\n<p>3、</p>\n<p>FIFO：支持单队列，先进先出，同一时间只有一个任务执行，并发度非常低，在企业里面不会使用</p>\n<p>容量：支持多队列，底层由多个FIFO调度器组成，优先满足先进队列的任务，资源不够的时候会先其他队列借资源，其他队列需要该资源时会直接抢过来，自己不够找帮手，帮手没事还好，有事帮手就不会帮你干，并发度一般</p>\n<p>公平：支持多队列，同一时间把所有任务全部启动，所有任务公平享有获得资源的权利，雨露均沾，并发度最高，</p>\n<p>6、如何选择：电脑服务器性能较好，对并发度要求比较高选择公平调度器（上市公司，大仓），如果电脑服务器比较差，对并发度要求不是特别高，就可以选择容量调度器（中小型公司）</p>\n<p>7、在企业开发时如何创建队列</p>\n<p>容量调度器默认就一个default队列，其他队列需要自己去创建，如何创建</p>\n<ul>\n<li><p>按照执行任务的框架引擎：hive、spark、flink，等等队列</p>\n</li>\n<li><p>按照业务模块创建（较多使用）：登录注册、订单、物流…</p>\n</li>\n</ul>\n<p>降级使用：在某些极端场景下，例如双11，那时候登录注册的人会很少，但是订单物流都会很多，就可以直接不允许注册登录，把那个队列的资源分配给别人使用，优先保证核心任务的正常执行</p>\n<p>8、Yarn的工作机制（笔试）</p>\n<p>管借账的</p>\n<p>job，向集群提交一个applicationid，然后给你一个泰泰，然你准备材料，你放到台台上，然后告诉rm我提交好了，再申请运行appmaster整个job的老大，管理整个作业，然后就很多人都在提交，放在了队列上，刚刚说的，然后按照调度策略，进行调度，以容量为例，然后先发钱，发个nm的容器，作业就在容器里面开启applicationmaster，appmaseter去读刚刚提交的材料，发现有两个切片，于是向rm申请我要运行两个maptask，然后申请了两份资源（容器），来运行maptask，appmaster喊开始执行然后map &#x3D;&gt; shuffle &#x3D;&gt; 落盘到对应的分区里，然后appmaster跟rm说我要运行reducetask，又申请两个资源，每个reducetask拉取自己分区的数据，然后reduce执行结束，最后appmaster说我要释放资源，然后资源释放</p>\n<p>yarn.schem.</p>\n<h2 id=\"数据倾斜\"><a href=\"#数据倾斜\" class=\"headerlink\" title=\"数据倾斜\"></a>数据倾斜</h2><h1 id=\"三、zookeeper\"><a href=\"#三、zookeeper\" class=\"headerlink\" title=\"三、zookeeper\"></a>三、zookeeper</h1><p>安装多少台：奇数台</p>\n<table>\n<thead>\n<tr>\n<th>服务器台数</th>\n<th>zk的台数</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>10</td>\n<td>3</td>\n</tr>\n<tr>\n<td>20</td>\n<td>5</td>\n</tr>\n<tr>\n<td>50</td>\n<td>7</td>\n</tr>\n<tr>\n<td>100</td>\n<td>11</td>\n</tr>\n</tbody></table>\n<p>台数越多：提高了数据可靠性，但是增加了通信延迟（举手表决需要通信），降低了效率</p>\n<p>选举机制：</p>\n<p>半数机制</p>\n<p>常用命令：</p>\n<p>ls get create delete</p>\n<h1 id=\"四、flume\"><a href=\"#四、flume\" class=\"headerlink\" title=\"四、flume\"></a>四、flume</h1><p><strong>一、三个组成</strong></p>\n<p>source</p>\n<p>​    Q：选择什么？</p>\n<p>​    A：taildir source，</p>\n<p>​    Q：为什么选择</p>\n<p>​    A：支持断点续传，多目录</p>\n<p>​    于什么时候产生？</p>\n<p>​    该source于Apache1.7 cdh1.6 产生</p>\n<p>​    没有taildir source之前怎么实现断点续传？</p>\n<p>​    自定义source，</p>\n<p>​    具体实现？</p>\n<p>​    （Apache 1.7源码）</p>\n<p>​    taildir source挂了会有什么影响？</p>\n<p>​    记录了offset，数据不会丢，但是数据有可能重复（有可能是先写到出然后还没来得及写offset就挂掉）</p>\n<p>​    Q：重复数据怎么解决</p>\n<p>​    A：不处理提高传输效率，交给下一级处理（在hive的dwd层处理，sparkstreaming，使用groupby或者开窗处理，redis）。处理使用    事务（自定义source实现）</p>\n<p>​    该source是否支持递归遍历文件夹读取数据</p>\n<p>​    不支持，只能自定义source，分成两部分（一部分遍历文件夹 + taildir读取文件函数）</p>\n<p>channel</p>\n<p>有哪些channel？各自的特点？</p>\n<ul>\n<li><p>memory channel：基于内存，可靠性低，传输效率高</p>\n</li>\n<li><p>file channel：基于磁盘，可靠性高，传输效率低</p>\n</li>\n<li><p>kafka channel：数据存储在kafka里面，数据基于磁盘，可靠性高，传输性能高于memorychannel + kafkasink。写kafka最好这样用</p>\n</li>\n</ul>\n<p>kafkachannel什么时候产生的</p>\n<p>Apache1.6产生，但是当时没火起来，因为传输数据总是带着头信息加上内容，后续需要额外清洗，去掉头，虽然提供了参数可以不要头但是没有起作用，于Apache1.7问题解决了，火了。</p>\n<p>如何选择？</p>\n<p>如果下一级是kafka优先选择kafkachannel，</p>\n<p>如果不是的话：对可靠性要求比较高，如金融行业，可以使用file channel，如果只是普通的日志，对可靠性要求不高，对速度要求高的选择memory channel</p>\n<p>hdfs sink</p>\n<p>小文件问题，不做控制会产生大量的小文件，调整三个参数</p>\n<p>文件大小：128m，滚动一次形成一个文件</p>\n<p>文件时间：1个小时或者2个小时（取一个回答）</p>\n<p>event个数：0</p>\n<p><strong>二、三个器</strong></p>\n<p>1）拦截器</p>\n<p>ETL拦截器 判断json的完整性（是否是{开头哦，是否是}结尾）</p>\n<p>事件拦截器 event 和 start</p>\n<p>event看topic</p>\n<p>将source按类分，发到不同的topic</p>\n<p>2）自定义拦截器：</p>\n<p>定义类，实现interceptor接口，重写4个方法（初始化，关闭资源，单event处理，多event处理，builder）</p>\n<p>打包上传到flume的lib包下，在配置文件中关联拦截器（全类名 $builder）</p>\n<p>3）不用拦截器行不行</p>\n<p>可以，就在hive的dwd层或者sparkstreaming内部解析</p>\n<p>选择器</p>\n<p>有几种？</p>\n<p>两种</p>\n<p>replicating（默认）：把数据发往下一级所有通道</p>\n<p>multiplexing：把数据选择性发往指定通道</p>\n<p>3）监控器</p>\n<p>Ganglia监控source向channelput的时候尝试提交的次数远远大于channel实际收到的次数，说明出现了大量的重试，就需要优化flume</p>\n<p>怎么优化呢？</p>\n<p>自身：单台flume在flume-env.sh增加内存</p>\n<p>找兄弟：增加flume台数（怎么增加，先增加日志服务器，把后续服务打通，然后通过nginx引过来）</p>\n<p>日志服务器配置（阿里云）：16g&#x2F;32g&#x2F;64g，只是部署一个springboot程序和一个flume</p>\n<p>选择器</p>\n<p>监控器</p>\n<p><strong>三、优化</strong></p>\n<p>filechannel 能配置多磁盘就配置多磁盘，能够提高吞吐量</p>\n<p>hdfssink，小文件，文件大小，128m，文件时间1-2h，event个数0个</p>\n<p>监控</p>\n<p>自身：单台flume在flume-env.sh增加内存</p>\n<p>找兄弟：增加flume台数</p>\n<p>挂了怎么办</p>\n<p>memorychannel有可能丢数据（该channel默认100个event，而filechannel默认100万个event）</p>\n<p>如果是taildirsource不会丢数据，但是有可能重复数据</p>\n<h1 id=\"五、kafka-23件事\"><a href=\"#五、kafka-23件事\" class=\"headerlink\" title=\"五、kafka 23件事\"></a>五、kafka 23件事</h1><h2 id=\"1、基本信息\"><a href=\"#1、基本信息\" class=\"headerlink\" title=\"1、基本信息\"></a>1、基本信息</h2><p>1）组成：生产者，broker，消费者，zk</p>\n<p>2）zk中存储了哪些信息：broker的id，topic的相关信息，低版本存储有消费者信息，高版本没有</p>\n<p>3）安装多少台？2 *（v * n &#x2F; 100) +1 &#x3D;y(企业中大部分都是三个)</p>\n<p>​    v：生产者峰值生成速率</p>\n<p>​    n：副本个数</p>\n<p>​    y：最终结果</p>\n<p>​    副本和台数固定了的话，那么生成速率就有其上限</p>\n<p>4）</p>\n<p>​    生产者峰值生成速率：需要压测；</p>\n<p>​    副本：默认是1，企业中通常配置2-3个（为什么这样配，副本越多，可靠性越高，增加了磁盘io，效率低下了）</p>\n<p>5）kafka里面的数据量问题</p>\n<p>​    100万日活，每个人产生100条日志数据，一天可以产生1亿条日志数据，一条数据大概0.5k到2k之间，一般取1k</p>\n<p>​    平均速度：1亿 &#x2F; 24 * 3600s &#x3D; 1150条&#x2F;秒 &#x3D;&gt; 说成1千多条就行 &#x3D;&gt; 大概1m&#x2F;s</p>\n<p>​    峰值速度：平均速度的20倍以上，每秒大约2万条数据左右，数据量大小20m&#x2F;s左右，在3台机器和2个副本的条件下，生成速率上限为50m&#x2F;s</p>\n<p>6）kafka中数据保存多久</p>\n<p>​    默认一周，其实保存3天就可以了，当天数据当天就消费了最多第二天多一点点</p>\n<p>7）kafka磁盘预留多大</p>\n<p>​    100g（1亿条 * 1kb &#x3D; 100G），副本是2，保存3天，加上一定的余量（30%-20%）&#x3D;&gt; 100G * 2 * 3 &#x2F;0.7 &#x3D; 857G&#x3D;&gt;1T</p>\n<p>8）kafka可以做监控</p>\n<p>​    kafka manager或者kafkaEgale，</p>\n<p>9）kafka的分区</p>\n<p>​    先设置一个分区，然后对其压测，测生产者的峰值生成速率tp和消费者消费的峰值速率tc，同时要有一个kafka吞吐量的预期（希望的t） </p>\n<p>​    分区数 &#x3D; t &#x2F; min(tp, tc)，例如t &#x3D;100m&#x2F;s,tp&#x3D;40m&#x2F;s,tc&#x3D;50m&#x2F;s，则分区数 &#x3D; 100&#x2F;40 &#x3D;2.5 &#x3D;&gt; 3个分区。除较小的，得到的就是较大的，一般企业中设置3-10个分区。</p>\n<p>10）分区分配策略</p>\n<p>​    range（默认）：假设10个分区，三个消费者线程消费，</p>\n<p>​        c1: 0,1,2,3 &#x3D;&gt; 容易产生数据倾斜，除不尽的放在了低消费者</p>\n<p>​        c2: 4,5,6</p>\n<p>​        c3: 7,8,9</p>\n<p>​    </p>\n<p>​    roundrobin：全部随机使用hash的方式随机打散，按hash排序，然后再轮询</p>\n<p>11）ISR</p>\n<p>​    主要解决leader挂了谁当老大，在isr队列里的都有机会当老大。</p>\n<p>​        旧版本：延迟时间、延迟条数</p>\n<p>​        新版本：延迟时间</p>\n<h2 id=\"2、挂了\"><a href=\"#2、挂了\" class=\"headerlink\" title=\"2、挂了\"></a>2、挂了</h2><p>短时间，内会存储在flume channel里面</p>\n<p>长时间，日志服务器保存30天数据</p>\n<h2 id=\"3、丢了\"><a href=\"#3、丢了\" class=\"headerlink\" title=\"3、丢了\"></a>3、丢了</h2><p>ack</p>\n<ul>\n<li>0：发送过来就不管了，效率最高，可靠性最低，容易丢数据，生产环境基本不用</li>\n<li>1：等待leader写好，然后leader应答，效率一般，可靠性一般。</li>\n<li>-1：要leader和Follower共同应答，要全部都写好，效率最差，可靠性最高。</li>\n</ul>\n<p>生产环境下：1一般传输普通日志，-1跟钱相关或者金融企业。</p>\n<h2 id=\"4、重复了\"><a href=\"#4、重复了\" class=\"headerlink\" title=\"4、重复了\"></a>4、重复了</h2><h2 id=\"5、积压了\"><a href=\"#5、积压了\" class=\"headerlink\" title=\"5、积压了\"></a>5、积压了</h2><h2 id=\"6、优化\"><a href=\"#6、优化\" class=\"headerlink\" title=\"6、优化\"></a>6、优化</h2><h2 id=\"7、其他\"><a href=\"#7、其他\" class=\"headerlink\" title=\"7、其他\"></a>7、其他</h2>","feature":true,"text":"一、Linux &amp; Shell总结ps -ef 只执行ps命令，默认是显示当前控制台下属于当前用户的进程； 参数 -e 显示运行在系统上的所有进程 参数 -f 扩展显示输出 UID 启动进程的用户 PID 进程的进程号 PPID 父进程进程号 C cpu使用率 STIME...","link":"","photos":[],"count_time":{"symbolsCount":"6k","symbolsTime":"5 mins."},"categories":[],"tags":[],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%B8%80%E3%80%81Linux-amp-Shell%E6%80%BB%E7%BB%93\"><span class=\"toc-text\">一、Linux &amp; Shell总结</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Hadoop\"><span class=\"toc-text\">Hadoop</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%85%A5%E9%97%A8\"><span class=\"toc-text\">入门</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#HDFS\"><span class=\"toc-text\">HDFS</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#MapReduce\"><span class=\"toc-text\">MapReduce</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#YARN\"><span class=\"toc-text\">YARN</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C\"><span class=\"toc-text\">数据倾斜</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%B8%89%E3%80%81zookeeper\"><span class=\"toc-text\">三、zookeeper</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%9B%9B%E3%80%81flume\"><span class=\"toc-text\">四、flume</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E4%BA%94%E3%80%81kafka-23%E4%BB%B6%E4%BA%8B\"><span class=\"toc-text\">五、kafka 23件事</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#1%E3%80%81%E5%9F%BA%E6%9C%AC%E4%BF%A1%E6%81%AF\"><span class=\"toc-text\">1、基本信息</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#2%E3%80%81%E6%8C%82%E4%BA%86\"><span class=\"toc-text\">2、挂了</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#3%E3%80%81%E4%B8%A2%E4%BA%86\"><span class=\"toc-text\">3、丢了</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#4%E3%80%81%E9%87%8D%E5%A4%8D%E4%BA%86\"><span class=\"toc-text\">4、重复了</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#5%E3%80%81%E7%A7%AF%E5%8E%8B%E4%BA%86\"><span class=\"toc-text\">5、积压了</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#6%E3%80%81%E4%BC%98%E5%8C%96\"><span class=\"toc-text\">6、优化</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#7%E3%80%81%E5%85%B6%E4%BB%96\"><span class=\"toc-text\">7、其他</span></a></li></ol></li></ol>","author":{"name":"Cencus","slug":"blog-author","avatar":"https://gitee.com/cencus/blog-image/raw/master/blogImage/1648381409561.jpg","link":"/","description":"stay hungry, stay foolish.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"prev_post":{},"next_post":{"title":"serverlet","uid":"e090f92b1230f61edcb4c749584fc402","slug":"serverlet","date":"2022-04-27T04:28:43.000Z","updated":"2022-04-27T04:52:02.602Z","comments":true,"path":"api/articles/serverlet.json","keywords":null,"cover":null,"text":"ServerLet响应格式 响应行：版本，状态码，消息 头：附加信息 空行：就是空行 响应实体：正文 常见状态码： 第一个定义类型，后面没有分类作用，分为5中类型 1xx 信息 服务器收到请求 2xx 成功 操作被接受并处理 3xx 重定向 需要进一步的操作以完成请求 4xx 客...","link":"","photos":[],"count_time":{"symbolsCount":605,"symbolsTime":"1 mins."},"categories":[],"tags":[],"author":{"name":"Cencus","slug":"blog-author","avatar":"https://gitee.com/cencus/blog-image/raw/master/blogImage/1648381409561.jpg","link":"/","description":"stay hungry, stay foolish.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true}}