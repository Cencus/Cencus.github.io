{"name":"spark","slug":"spark","count":2,"postlist":[{"title":"spark-sql","uid":"c4e1f631332880dad580bd689797a6a3","slug":"spark-sql","date":"2022-04-16T12:49:55.000Z","updated":"2022-04-18T03:02:09.738Z","comments":true,"path":"api/articles/spark-sql.json","keywords":null,"cover":[],"text":"第1章 SparkSQL 概述1.3 SparkSQL 特点1.3.1 易整合无缝的整合了 SQL 查询和 Spark 编程 1.3.2 统一的数据访问使用相同的方式连接不同的数据源 1.3.3 兼容Hive 在已有的仓库上直接运行 SQL 或者 HiveQL 1.3.4 标准数...","link":"","photos":[],"count_time":{"symbolsCount":"16k","symbolsTime":"15 mins."},"categories":[],"tags":[{"name":"spark","slug":"spark","count":2,"path":"api/tags/spark.json"}],"author":{"name":"Cencus","slug":"blog-author","avatar":"https://gitee.com/cencus/blog-image/raw/master/blogImage/1648381409561.jpg","link":"/","description":"stay hungry, stay foolish.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}},{"title":"spark","uid":"e04902dcdb07e2ad1898c41f1efa8f40","slug":"spark","date":"2022-04-08T12:55:34.000Z","updated":"2022-04-17T02:45:10.830Z","comments":true,"path":"api/articles/spark.json","keywords":null,"cover":[],"text":"第3章 spark运行环境3.1 local模式3.2 standalone模式3.3 yarn模式（公司常用）3.4 k8s &amp; Mesos模式3.5 windows模式3.5.2 本地环境3.7 端口号➢ Spark 查看当前 Spark-shell 运行任务情况端口...","link":"","photos":[],"count_time":{"symbolsCount":"20k","symbolsTime":"18 mins."},"categories":[],"tags":[{"name":"spark","slug":"spark","count":2,"path":"api/tags/spark.json"}],"author":{"name":"Cencus","slug":"blog-author","avatar":"https://gitee.com/cencus/blog-image/raw/master/blogImage/1648381409561.jpg","link":"/","description":"stay hungry, stay foolish.","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}]}